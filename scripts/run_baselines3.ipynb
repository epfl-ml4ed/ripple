{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d356a070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ee185b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c33683a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4088eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/../ML4ED/Raindrop/code/baselines\n"
     ]
    }
   ],
   "source": [
    "%cd Raindrop/code/baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e016dd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "wandb = False\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, average_precision_score, precision_score, recall_score, f1_score\n",
    "from models import TransformerModel, TransformerModel2, SEFT\n",
    "from utils_phy12 import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc20a1b3",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c3da304",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOOCs_list = [\n",
    "'villesafricaines_002.csv',\n",
    " 'villesafricaines_003.csv',\n",
    " 'microcontroleurs_004.csv',\n",
    " 'dsp_004.csv',\n",
    " 'hwts_001.csv',\n",
    " 'dsp_001.csv',\n",
    " 'progfun_002.csv',\n",
    " 'microcontroleurs_003.csv',\n",
    " 'geomatique_003.csv',\n",
    " 'villesafricaines_001.csv',\n",
    " 'progfun_003.csv',\n",
    " 'dsp_002.csv',\n",
    " 'structures_002.csv',\n",
    " 'initprogcpp_001.csv',\n",
    " 'analysenumerique_003.csv',\n",
    " 'microcontroleurs_006.csv',\n",
    " 'dsp_005.csv',\n",
    " 'hwts_002.csv',\n",
    " 'dsp_006.csv',\n",
    " 'analysenumerique_002.csv',\n",
    " 'structures_003.csv',\n",
    " 'microcontroleurs_005.csv',\n",
    " 'venture_001.csv',\n",
    " 'analysenumerique_001.csv',\n",
    " 'cpp_fr_001.csv',\n",
    " 'structures_001.csv'\n",
    "]\n",
    "MOOCs_list = [i.replace(\"_\", \"-\").split('.')[0] for i in MOOCs_list]\n",
    "\n",
    "dims4 = [12,\n",
    " 12,\n",
    " 13,\n",
    " 12,\n",
    " 12,\n",
    " 6,\n",
    " 12,\n",
    " 13,\n",
    " 12,\n",
    " 12,\n",
    " 12,\n",
    " 12,\n",
    " 13,\n",
    " 13,\n",
    " 6,\n",
    " 13,\n",
    " 12,\n",
    " 12,\n",
    " 12,\n",
    " 12,\n",
    " 13,\n",
    " 13,\n",
    " 12,\n",
    " 6,\n",
    " 13,\n",
    " 12]\n",
    "\n",
    "dims6 = [12,\n",
    " 12,\n",
    " 13,\n",
    " 12,\n",
    " 12,\n",
    " 6,\n",
    " 12,\n",
    " 13,\n",
    " 12,\n",
    " 12,\n",
    " 12,\n",
    " 12,\n",
    " 13,\n",
    " 13,\n",
    " 6,\n",
    " 13,\n",
    " 12,\n",
    " 12,\n",
    " 13,\n",
    " 12,\n",
    " 13,\n",
    " 13,\n",
    " 12,\n",
    " 6,\n",
    " 13,\n",
    " 12]\n",
    "dims = {40: dims4, 60: dims6}\n",
    "data_path = '/../data'\n",
    "percentile = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51064aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split id: 1\n",
      "1966 234 247 1966 234 247\n",
      "[176] [21] [24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1966, 1000, 24]) torch.Size([1966, 9]) torch.Size([1966, 1000, 1]) torch.Size([1966])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6899, aupr_val: 23.17, auc_val: 66.35\n",
      "**[S] Epoch 0, aupr_val: 23.1653, auc_val: 66.3537 **\n",
      "Validation: Epoch 1,  val_loss:0.6917, aupr_val: 20.19, auc_val: 66.91\n",
      "**[S] Epoch 1, aupr_val: 20.1857, auc_val: 66.9126 **\n",
      "Validation: Epoch 2,  val_loss:0.6963, aupr_val: 25.06, auc_val: 72.70\n",
      "**[S] Epoch 2, aupr_val: 25.0593, auc_val: 72.7029 **\n",
      "Validation: Epoch 3,  val_loss:0.6878, aupr_val: 33.20, auc_val: 79.25\n",
      "**[S] Epoch 3, aupr_val: 33.2033, auc_val: 79.2533 **\n",
      "Validation: Epoch 4,  val_loss:0.6899, aupr_val: 33.29, auc_val: 79.83\n",
      "**[S] Epoch 4, aupr_val: 33.2917, auc_val: 79.8346 **\n",
      "Validation: Epoch 5,  val_loss:0.6781, aupr_val: 37.46, auc_val: 82.88\n",
      "**[S] Epoch 5, aupr_val: 37.4617, auc_val: 82.8750 **\n",
      "Validation: Epoch 6,  val_loss:0.6625, aupr_val: 37.42, auc_val: 82.86\n",
      "Validation: Epoch 7,  val_loss:0.6665, aupr_val: 37.46, auc_val: 82.88\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.\n",
      "**[S] Epoch 7, aupr_val: 37.4617, auc_val: 82.8750 **\n",
      "Validation: Epoch 8,  val_loss:0.6622, aupr_val: 37.53, auc_val: 82.89\n",
      "**[S] Epoch 8, aupr_val: 37.5278, auc_val: 82.8862 **\n",
      "Validation: Epoch 9,  val_loss:0.6579, aupr_val: 37.67, auc_val: 82.92\n",
      "**[S] Epoch 9, aupr_val: 37.6727, auc_val: 82.9197 **\n",
      "Validation: Epoch 10,  val_loss:0.6579, aupr_val: 37.50, auc_val: 82.88\n",
      "Validation: Epoch 11,  val_loss:0.6603, aupr_val: 37.56, auc_val: 82.90\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 12,  val_loss:0.6602, aupr_val: 37.57, auc_val: 82.90\n",
      "Validation: Epoch 13,  val_loss:0.6600, aupr_val: 37.57, auc_val: 82.85\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 14,  val_loss:0.6600, aupr_val: 37.53, auc_val: 82.88\n",
      "Validation: Epoch 15,  val_loss:0.6599, aupr_val: 37.61, auc_val: 82.88\n",
      "Epoch 00016: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 16,  val_loss:0.6599, aupr_val: 37.46, auc_val: 82.88\n",
      "Validation: Epoch 17,  val_loss:0.6599, aupr_val: 37.46, auc_val: 82.88\n",
      "Epoch 00018: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 18,  val_loss:0.6599, aupr_val: 37.46, auc_val: 82.88\n",
      "Validation: Epoch 19,  val_loss:0.6599, aupr_val: 37.46, auc_val: 82.88\n",
      "Total Time elapsed: 0.094 mins\n",
      "                 course  percentile       acc      bac       auc     auprc\n",
      "0  villesafricaines-002          40  0.923333  0.59692  0.419611  0.148843\n",
      "Split id: 1\n",
      "2125 263 268 2125 263 268\n",
      "[186] [23] [24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2125, 1000, 24]) torch.Size([2125, 9]) torch.Size([2125, 1000, 1]) torch.Size([2125])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6798, aupr_val: 43.51, auc_val: 79.00\n",
      "**[S] Epoch 0, aupr_val: 43.5120, auc_val: 79.0036 **\n",
      "Validation: Epoch 1,  val_loss:0.6839, aupr_val: 47.85, auc_val: 82.48\n",
      "**[S] Epoch 1, aupr_val: 47.8467, auc_val: 82.4819 **\n",
      "Validation: Epoch 2,  val_loss:0.6783, aupr_val: 48.21, auc_val: 82.41\n",
      "Validation: Epoch 3,  val_loss:0.6688, aupr_val: 46.52, auc_val: 82.19\n",
      "Validation: Epoch 4,  val_loss:0.6685, aupr_val: 46.52, auc_val: 82.19\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 5,  val_loss:0.6685, aupr_val: 46.52, auc_val: 82.19\n",
      "Validation: Epoch 6,  val_loss:0.6670, aupr_val: 46.52, auc_val: 82.19\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 7,  val_loss:0.6669, aupr_val: 46.52, auc_val: 82.19\n",
      "Validation: Epoch 8,  val_loss:0.6669, aupr_val: 46.52, auc_val: 82.19\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 9,  val_loss:0.6669, aupr_val: 46.52, auc_val: 82.19\n",
      "Validation: Epoch 10,  val_loss:0.6669, aupr_val: 46.52, auc_val: 82.19\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 11,  val_loss:0.6669, aupr_val: 46.52, auc_val: 82.19\n",
      "Validation: Epoch 12,  val_loss:0.6669, aupr_val: 46.52, auc_val: 82.19\n",
      "Epoch 00013: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 13,  val_loss:0.6669, aupr_val: 46.52, auc_val: 82.19\n",
      "Validation: Epoch 14,  val_loss:0.6669, aupr_val: 46.52, auc_val: 82.19\n",
      "Validation: Epoch 15,  val_loss:0.6669, aupr_val: 46.52, auc_val: 82.19\n",
      "Validation: Epoch 16,  val_loss:0.6669, aupr_val: 46.52, auc_val: 82.19\n",
      "Validation: Epoch 17,  val_loss:0.6669, aupr_val: 46.52, auc_val: 82.19\n",
      "Validation: Epoch 18,  val_loss:0.6669, aupr_val: 46.52, auc_val: 82.19\n",
      "Validation: Epoch 19,  val_loss:0.6669, aupr_val: 46.52, auc_val: 82.19\n",
      "Total Time elapsed: 0.076 mins\n",
      "                 course  percentile       acc       bac       auc     auprc\n",
      "0  villesafricaines-002          60  0.886667  0.596014  0.415157  0.219742\n",
      "Split id: 1\n",
      "1431 174 180 1431 174 180\n",
      "[180] [22] [23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1431, 1000, 24]) torch.Size([1431, 9]) torch.Size([1431, 1000, 1]) torch.Size([1431])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6966, aupr_val: 21.09, auc_val: 61.23\n",
      "**[S] Epoch 0, aupr_val: 21.0922, auc_val: 61.2291 **\n",
      "Validation: Epoch 1,  val_loss:0.6880, aupr_val: 30.42, auc_val: 75.19\n",
      "**[S] Epoch 1, aupr_val: 30.4208, auc_val: 75.1944 **\n",
      "Validation: Epoch 2,  val_loss:0.6896, aupr_val: 33.77, auc_val: 78.72\n",
      "**[S] Epoch 2, aupr_val: 33.7675, auc_val: 78.7231 **\n",
      "Validation: Epoch 3,  val_loss:0.6849, aupr_val: 35.09, auc_val: 78.24\n",
      "Validation: Epoch 4,  val_loss:0.6846, aupr_val: 35.02, auc_val: 78.21\n",
      "Validation: Epoch 5,  val_loss:0.6757, aupr_val: 23.97, auc_val: 43.85\n",
      "Epoch 00006: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 6,  val_loss:0.6813, aupr_val: 28.54, auc_val: 65.36\n",
      "Validation: Epoch 7,  val_loss:0.6843, aupr_val: 35.98, auc_val: 78.24\n",
      "Validation: Epoch 8,  val_loss:0.6816, aupr_val: 26.30, auc_val: 55.34\n",
      "Validation: Epoch 9,  val_loss:0.6783, aupr_val: 24.42, auc_val: 43.88\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 10,  val_loss:0.6782, aupr_val: 24.42, auc_val: 43.88\n",
      "Validation: Epoch 11,  val_loss:0.6781, aupr_val: 24.42, auc_val: 43.88\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 12,  val_loss:0.6782, aupr_val: 24.42, auc_val: 43.90\n",
      "Validation: Epoch 13,  val_loss:0.6782, aupr_val: 24.42, auc_val: 43.91\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 14,  val_loss:0.6782, aupr_val: 24.42, auc_val: 43.88\n",
      "Validation: Epoch 15,  val_loss:0.6782, aupr_val: 24.42, auc_val: 43.91\n",
      "Epoch 00016: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 16,  val_loss:0.6782, aupr_val: 24.42, auc_val: 43.91\n",
      "Validation: Epoch 17,  val_loss:0.6782, aupr_val: 24.42, auc_val: 43.88\n",
      "Validation: Epoch 18,  val_loss:0.6782, aupr_val: 24.42, auc_val: 43.90\n",
      "Validation: Epoch 19,  val_loss:0.6782, aupr_val: 24.42, auc_val: 43.88\n",
      "Total Time elapsed: 0.078 mins\n",
      "                 course  percentile       acc       bac      auc    auprc\n",
      "0  villesafricaines-003          40  0.893519  0.653188  0.91203  0.50532\n",
      "Split id: 1\n",
      "1532 187 194 1532 187 194\n",
      "[181] [22] [23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1532, 1000, 24]) torch.Size([1532, 9]) torch.Size([1532, 1000, 1]) torch.Size([1532])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6829, aupr_val: 22.09, auc_val: 38.82\n",
      "**[S] Epoch 0, aupr_val: 22.0943, auc_val: 38.8154 **\n",
      "Validation: Epoch 1,  val_loss:0.6637, aupr_val: 25.37, auc_val: 38.90\n",
      "**[S] Epoch 1, aupr_val: 25.3726, auc_val: 38.8981 **\n",
      "Validation: Epoch 2,  val_loss:0.6719, aupr_val: 25.72, auc_val: 38.90\n",
      "Validation: Epoch 3,  val_loss:0.6501, aupr_val: 25.73, auc_val: 38.87\n",
      "Validation: Epoch 4,  val_loss:0.6613, aupr_val: 25.04, auc_val: 38.84\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 5,  val_loss:0.6552, aupr_val: 25.04, auc_val: 38.84\n",
      "Validation: Epoch 6,  val_loss:0.6478, aupr_val: 25.04, auc_val: 38.84\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 7,  val_loss:0.6473, aupr_val: 25.04, auc_val: 38.84\n",
      "Validation: Epoch 8,  val_loss:0.6470, aupr_val: 25.04, auc_val: 38.84\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 9,  val_loss:0.6470, aupr_val: 25.04, auc_val: 38.84\n",
      "Validation: Epoch 10,  val_loss:0.6470, aupr_val: 25.04, auc_val: 38.84\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 11,  val_loss:0.6470, aupr_val: 25.04, auc_val: 38.84\n",
      "Validation: Epoch 12,  val_loss:0.6470, aupr_val: 25.04, auc_val: 38.84\n",
      "Epoch 00013: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 13,  val_loss:0.6470, aupr_val: 25.04, auc_val: 38.84\n",
      "Validation: Epoch 14,  val_loss:0.6470, aupr_val: 25.04, auc_val: 38.84\n",
      "Validation: Epoch 15,  val_loss:0.6470, aupr_val: 25.04, auc_val: 38.84\n",
      "Validation: Epoch 16,  val_loss:0.6470, aupr_val: 25.04, auc_val: 38.84\n",
      "Validation: Epoch 17,  val_loss:0.6470, aupr_val: 25.04, auc_val: 38.84\n",
      "Validation: Epoch 18,  val_loss:0.6470, aupr_val: 25.04, auc_val: 38.84\n",
      "Validation: Epoch 19,  val_loss:0.6470, aupr_val: 25.04, auc_val: 38.84\n",
      "Total Time elapsed: 0.074 mins\n",
      "                 course  percentile       acc       bac       auc    auprc\n",
      "0  villesafricaines-003          60  0.912037  0.701847  0.559135  0.32307\n",
      "Split id: 1\n",
      "1740 215 219 1740 215 219\n",
      "[181] [23] [22]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1740, 1000, 26]) torch.Size([1740, 9]) torch.Size([1740, 1000, 1]) torch.Size([1740])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6957, aupr_val: 6.38, auc_val: 16.41\n",
      "**[S] Epoch 0, aupr_val: 6.3807, auc_val: 16.4062 **\n",
      "Validation: Epoch 1,  val_loss:0.6930, aupr_val: 6.38, auc_val: 16.41\n",
      "Validation: Epoch 2,  val_loss:0.6897, aupr_val: 6.38, auc_val: 16.41\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.6905, aupr_val: 6.38, auc_val: 16.41\n",
      "Validation: Epoch 4,  val_loss:0.6912, aupr_val: 6.38, auc_val: 16.41\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.6911, aupr_val: 6.38, auc_val: 16.41\n",
      "Validation: Epoch 6,  val_loss:0.6912, aupr_val: 6.38, auc_val: 16.41\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.6912, aupr_val: 6.38, auc_val: 16.41\n",
      "Validation: Epoch 8,  val_loss:0.6912, aupr_val: 6.38, auc_val: 16.41\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.6912, aupr_val: 6.38, auc_val: 16.41\n",
      "Validation: Epoch 10,  val_loss:0.6912, aupr_val: 6.38, auc_val: 16.41\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.6912, aupr_val: 6.38, auc_val: 16.41\n",
      "Validation: Epoch 12,  val_loss:0.6912, aupr_val: 6.38, auc_val: 16.41\n",
      "Validation: Epoch 13,  val_loss:0.6912, aupr_val: 6.38, auc_val: 16.41\n",
      "Validation: Epoch 14,  val_loss:0.6912, aupr_val: 6.38, auc_val: 16.41\n",
      "Validation: Epoch 15,  val_loss:0.6912, aupr_val: 6.38, auc_val: 16.41\n",
      "Validation: Epoch 16,  val_loss:0.6912, aupr_val: 6.38, auc_val: 16.41\n",
      "Validation: Epoch 17,  val_loss:0.6912, aupr_val: 6.40, auc_val: 16.41\n",
      "Validation: Epoch 18,  val_loss:0.6912, aupr_val: 6.40, auc_val: 16.41\n",
      "Validation: Epoch 19,  val_loss:0.6912, aupr_val: 6.38, auc_val: 16.41\n",
      "Total Time elapsed: 0.081 mins\n",
      "                 course  percentile       acc       bac       auc     auprc\n",
      "0  microcontroleurs-004          40  0.300353  0.599415  0.389548  0.110775\n",
      "Split id: 1\n",
      "1965 246 243 1965 246 243\n",
      "[186] [23] [23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1965, 1000, 26]) torch.Size([1965, 9]) torch.Size([1965, 1000, 1]) torch.Size([1965])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6886, aupr_val: 38.74, auc_val: 78.72\n",
      "**[S] Epoch 0, aupr_val: 38.7409, auc_val: 78.7190 **\n",
      "Validation: Epoch 1,  val_loss:0.6822, aupr_val: 25.24, auc_val: 45.15\n",
      "Validation: Epoch 2,  val_loss:0.6698, aupr_val: 23.86, auc_val: 44.74\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.6705, aupr_val: 24.21, auc_val: 44.91\n",
      "Validation: Epoch 4,  val_loss:0.6712, aupr_val: 24.21, auc_val: 44.91\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.6713, aupr_val: 24.21, auc_val: 44.91\n",
      "Validation: Epoch 6,  val_loss:0.6712, aupr_val: 24.21, auc_val: 44.91\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.6712, aupr_val: 24.21, auc_val: 44.91\n",
      "Validation: Epoch 8,  val_loss:0.6712, aupr_val: 24.21, auc_val: 44.91\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.6712, aupr_val: 24.21, auc_val: 44.91\n",
      "Validation: Epoch 10,  val_loss:0.6712, aupr_val: 24.21, auc_val: 44.91\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.6712, aupr_val: 24.21, auc_val: 44.91\n",
      "Validation: Epoch 12,  val_loss:0.6712, aupr_val: 24.21, auc_val: 44.91\n",
      "Validation: Epoch 13,  val_loss:0.6712, aupr_val: 24.21, auc_val: 44.91\n",
      "Validation: Epoch 14,  val_loss:0.6712, aupr_val: 24.21, auc_val: 44.91\n",
      "Validation: Epoch 15,  val_loss:0.6712, aupr_val: 24.21, auc_val: 44.91\n",
      "Validation: Epoch 16,  val_loss:0.6712, aupr_val: 24.21, auc_val: 44.91\n",
      "Validation: Epoch 17,  val_loss:0.6712, aupr_val: 24.21, auc_val: 44.91\n",
      "Validation: Epoch 18,  val_loss:0.6712, aupr_val: 24.21, auc_val: 44.91\n",
      "Validation: Epoch 19,  val_loss:0.6712, aupr_val: 24.21, auc_val: 44.91\n",
      "Total Time elapsed: 0.084 mins\n",
      "                 course  percentile       acc       bac       auc     auprc\n",
      "0  microcontroleurs-004          60  0.904594  0.571572  0.912709  0.366434\n",
      "Split id: 1\n",
      "1317 164 164 1317 164 164\n",
      "[226] [28] [29]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1317, 1000, 24]) torch.Size([1317, 9]) torch.Size([1317, 1000, 1]) torch.Size([1317])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6711, aupr_val: 18.71, auc_val: 46.64\n",
      "**[S] Epoch 0, aupr_val: 18.7051, auc_val: 46.6387 **\n",
      "Validation: Epoch 1,  val_loss:0.6692, aupr_val: 20.69, auc_val: 48.98\n",
      "**[S] Epoch 1, aupr_val: 20.6937, auc_val: 48.9758 **\n",
      "Validation: Epoch 2,  val_loss:0.6679, aupr_val: 21.20, auc_val: 49.05\n",
      "**[S] Epoch 2, aupr_val: 21.1982, auc_val: 49.0546 **\n",
      "Validation: Epoch 3,  val_loss:0.6582, aupr_val: 21.12, auc_val: 49.11\n",
      "**[S] Epoch 3, aupr_val: 21.1233, auc_val: 49.1071 **\n",
      "Validation: Epoch 4,  val_loss:0.6656, aupr_val: 21.80, auc_val: 49.24\n",
      "**[S] Epoch 4, aupr_val: 21.8028, auc_val: 49.2384 **\n",
      "Validation: Epoch 5,  val_loss:0.6580, aupr_val: 23.56, auc_val: 49.24\n",
      "Validation: Epoch 6,  val_loss:0.6642, aupr_val: 23.24, auc_val: 49.29\n",
      "**[S] Epoch 6, aupr_val: 23.2359, auc_val: 49.2910 **\n",
      "Validation: Epoch 7,  val_loss:0.6616, aupr_val: 24.13, auc_val: 49.26\n",
      "Validation: Epoch 8,  val_loss:0.6560, aupr_val: 24.35, auc_val: 49.61\n",
      "**[S] Epoch 8, aupr_val: 24.3496, auc_val: 49.6061 **\n",
      "Validation: Epoch 9,  val_loss:0.6626, aupr_val: 25.34, auc_val: 49.79\n",
      "**[S] Epoch 9, aupr_val: 25.3429, auc_val: 49.7899 **\n",
      "Validation: Epoch 10,  val_loss:0.6602, aupr_val: 25.86, auc_val: 49.79\n",
      "Validation: Epoch 11,  val_loss:0.6651, aupr_val: 25.98, auc_val: 49.84\n",
      "**[S] Epoch 11, aupr_val: 25.9766, auc_val: 49.8424 **\n",
      "Validation: Epoch 12,  val_loss:0.6642, aupr_val: 26.45, auc_val: 50.21\n",
      "**[S] Epoch 12, aupr_val: 26.4519, auc_val: 50.2101 **\n",
      "Validation: Epoch 13,  val_loss:0.6597, aupr_val: 26.95, auc_val: 51.68\n",
      "**[S] Epoch 13, aupr_val: 26.9516, auc_val: 51.6807 **\n",
      "Validation: Epoch 14,  val_loss:0.6615, aupr_val: 27.61, auc_val: 52.89\n",
      "**[S] Epoch 14, aupr_val: 27.6096, auc_val: 52.8887 **\n",
      "Validation: Epoch 15,  val_loss:0.6625, aupr_val: 27.40, auc_val: 52.52\n",
      "Validation: Epoch 16,  val_loss:0.6599, aupr_val: 27.60, auc_val: 52.89\n",
      "Epoch 00017: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 17,  val_loss:0.6616, aupr_val: 27.60, auc_val: 52.89\n",
      "Validation: Epoch 18,  val_loss:0.6610, aupr_val: 27.60, auc_val: 52.89\n",
      "Epoch 00019: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 19,  val_loss:0.6612, aupr_val: 27.60, auc_val: 52.89\n",
      "Total Time elapsed: 0.093 mins\n",
      "    course  percentile       acc       bac       auc     auprc\n",
      "0  dsp-004          40  0.873563  0.703448  0.730916  0.517699\n",
      "Split id: 1\n",
      "1350 167 166 1350 167 166\n",
      "[226] [28] [29]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1350, 1000, 24]) torch.Size([1350, 9]) torch.Size([1350, 1000, 1]) torch.Size([1350])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6476, aupr_val: 30.25, auc_val: 53.92\n",
      "**[S] Epoch 0, aupr_val: 30.2486, auc_val: 53.9183 **\n",
      "Validation: Epoch 1,  val_loss:0.6396, aupr_val: 30.14, auc_val: 54.05\n",
      "**[S] Epoch 1, aupr_val: 30.1373, auc_val: 54.0468 **\n",
      "Validation: Epoch 2,  val_loss:0.6499, aupr_val: 30.74, auc_val: 54.15\n",
      "**[S] Epoch 2, aupr_val: 30.7368, auc_val: 54.1495 **\n",
      "Validation: Epoch 3,  val_loss:0.6238, aupr_val: 31.78, auc_val: 54.30\n",
      "**[S] Epoch 3, aupr_val: 31.7762, auc_val: 54.3037 **\n",
      "Validation: Epoch 4,  val_loss:0.6399, aupr_val: 33.66, auc_val: 54.51\n",
      "**[S] Epoch 4, aupr_val: 33.6617, auc_val: 54.5092 **\n",
      "Validation: Epoch 5,  val_loss:0.6273, aupr_val: 35.29, auc_val: 54.43\n",
      "Validation: Epoch 6,  val_loss:0.6388, aupr_val: 35.90, auc_val: 54.61\n",
      "**[S] Epoch 6, aupr_val: 35.9000, auc_val: 54.6120 **\n",
      "Validation: Epoch 7,  val_loss:0.6411, aupr_val: 38.45, auc_val: 54.64\n",
      "**[S] Epoch 7, aupr_val: 38.4488, auc_val: 54.6377 **\n",
      "Validation: Epoch 8,  val_loss:0.6305, aupr_val: 38.90, auc_val: 54.66\n",
      "**[S] Epoch 8, aupr_val: 38.9030, auc_val: 54.6634 **\n",
      "Validation: Epoch 9,  val_loss:0.6414, aupr_val: 40.09, auc_val: 54.87\n",
      "**[S] Epoch 9, aupr_val: 40.0912, auc_val: 54.8690 **\n",
      "Validation: Epoch 10,  val_loss:0.6321, aupr_val: 40.59, auc_val: 55.10\n",
      "**[S] Epoch 10, aupr_val: 40.5900, auc_val: 55.1002 **\n",
      "Validation: Epoch 11,  val_loss:0.6270, aupr_val: 41.27, auc_val: 56.28\n",
      "**[S] Epoch 11, aupr_val: 41.2691, auc_val: 56.2821 **\n",
      "Validation: Epoch 12,  val_loss:0.6405, aupr_val: 41.64, auc_val: 58.36\n",
      "**[S] Epoch 12, aupr_val: 41.6422, auc_val: 58.3633 **\n",
      "Validation: Epoch 13,  val_loss:0.6247, aupr_val: 41.90, auc_val: 58.39\n",
      "**[S] Epoch 13, aupr_val: 41.9024, auc_val: 58.3890 **\n",
      "Validation: Epoch 14,  val_loss:0.6168, aupr_val: 42.17, auc_val: 58.70\n",
      "**[S] Epoch 14, aupr_val: 42.1696, auc_val: 58.6973 **\n",
      "Validation: Epoch 15,  val_loss:0.6199, aupr_val: 43.08, auc_val: 60.73\n",
      "**[S] Epoch 15, aupr_val: 43.0839, auc_val: 60.7271 **\n",
      "Validation: Epoch 16,  val_loss:0.6099, aupr_val: 42.30, auc_val: 58.77\n",
      "Validation: Epoch 17,  val_loss:0.6188, aupr_val: 43.40, auc_val: 61.09\n",
      "**[S] Epoch 17, aupr_val: 43.4048, auc_val: 61.0868 **\n",
      "Validation: Epoch 18,  val_loss:0.6181, aupr_val: 43.06, auc_val: 60.73\n",
      "Validation: Epoch 19,  val_loss:0.6213, aupr_val: 42.52, auc_val: 60.73\n",
      "Epoch 00020: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Total Time elapsed: 0.095 mins\n",
      "    course  percentile       acc       bac       auc     auprc\n",
      "0  dsp-004          60  0.885057  0.765517  0.790844  0.663529\n",
      "Split id: 1\n",
      "1074 138 136 1074 138 136\n",
      "[507] [64] [61]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1074, 1000, 24]) torch.Size([1074, 9]) torch.Size([1074, 1000, 1]) torch.Size([1074])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6943, aupr_val: 49.56, auc_val: 50.31\n",
      "**[S] Epoch 0, aupr_val: 49.5647, auc_val: 50.3062 **\n",
      "Validation: Epoch 1,  val_loss:0.6930, aupr_val: 49.57, auc_val: 50.33\n",
      "**[S] Epoch 1, aupr_val: 49.5728, auc_val: 50.3273 **\n",
      "Validation: Epoch 2,  val_loss:0.6924, aupr_val: 51.97, auc_val: 51.81\n",
      "**[S] Epoch 2, aupr_val: 51.9736, auc_val: 51.8053 **\n",
      "Validation: Epoch 3,  val_loss:0.6926, aupr_val: 52.03, auc_val: 52.02\n",
      "**[S] Epoch 3, aupr_val: 52.0308, auc_val: 52.0165 **\n",
      "Validation: Epoch 4,  val_loss:0.6915, aupr_val: 52.75, auc_val: 53.01\n",
      "**[S] Epoch 4, aupr_val: 52.7485, auc_val: 53.0089 **\n",
      "Validation: Epoch 5,  val_loss:0.6911, aupr_val: 54.68, auc_val: 54.76\n",
      "**[S] Epoch 5, aupr_val: 54.6773, auc_val: 54.7614 **\n",
      "Validation: Epoch 6,  val_loss:0.6900, aupr_val: 56.34, auc_val: 57.11\n",
      "**[S] Epoch 6, aupr_val: 56.3369, auc_val: 57.1052 **\n",
      "Validation: Epoch 7,  val_loss:0.6895, aupr_val: 56.34, auc_val: 57.11\n",
      "Validation: Epoch 8,  val_loss:0.6887, aupr_val: 56.35, auc_val: 57.17\n",
      "**[S] Epoch 8, aupr_val: 56.3548, auc_val: 57.1685 **\n",
      "Validation: Epoch 9,  val_loss:0.6877, aupr_val: 57.39, auc_val: 58.44\n",
      "**[S] Epoch 9, aupr_val: 57.3900, auc_val: 58.4354 **\n",
      "Validation: Epoch 10,  val_loss:0.6873, aupr_val: 57.49, auc_val: 58.44\n",
      "Validation: Epoch 11,  val_loss:0.6874, aupr_val: 57.39, auc_val: 58.41\n",
      "Validation: Epoch 12,  val_loss:0.6871, aupr_val: 56.97, auc_val: 58.41\n",
      "Epoch 00013: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 13,  val_loss:0.6870, aupr_val: 56.97, auc_val: 58.41\n",
      "Validation: Epoch 14,  val_loss:0.6874, aupr_val: 56.07, auc_val: 57.55\n",
      "Epoch 00015: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 15,  val_loss:0.6875, aupr_val: 56.01, auc_val: 57.38\n",
      "Validation: Epoch 16,  val_loss:0.6875, aupr_val: 56.01, auc_val: 57.38\n",
      "Epoch 00017: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 17,  val_loss:0.6875, aupr_val: 56.01, auc_val: 57.38\n",
      "Validation: Epoch 18,  val_loss:0.6875, aupr_val: 56.01, auc_val: 57.38\n",
      "Epoch 00019: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 19,  val_loss:0.6875, aupr_val: 56.01, auc_val: 57.38\n",
      "Total Time elapsed: 0.072 mins\n",
      "     course  percentile       acc      bac       auc     auprc\n",
      "0  hwts-001          40  0.528571  0.49301  0.594778  0.519926\n",
      "Split id: 1\n",
      "1104 139 140 1104 139 140\n",
      "[512] [64] [64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1104, 1000, 24]) torch.Size([1104, 9]) torch.Size([1104, 1000, 1]) torch.Size([1104])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6898, aupr_val: 49.66, auc_val: 47.42\n",
      "**[S] Epoch 0, aupr_val: 49.6618, auc_val: 47.4167 **\n",
      "Validation: Epoch 1,  val_loss:0.6886, aupr_val: 53.16, auc_val: 51.40\n",
      "**[S] Epoch 1, aupr_val: 53.1647, auc_val: 51.3958 **\n",
      "Validation: Epoch 2,  val_loss:0.6861, aupr_val: 60.91, auc_val: 61.15\n",
      "**[S] Epoch 2, aupr_val: 60.9142, auc_val: 61.1458 **\n",
      "Validation: Epoch 3,  val_loss:0.6843, aupr_val: 61.60, auc_val: 61.77\n",
      "**[S] Epoch 3, aupr_val: 61.6007, auc_val: 61.7708 **\n",
      "Validation: Epoch 4,  val_loss:0.6812, aupr_val: 61.45, auc_val: 61.73\n",
      "Validation: Epoch 5,  val_loss:0.6784, aupr_val: 60.61, auc_val: 61.69\n",
      "Epoch 00006: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 6,  val_loss:0.6786, aupr_val: 60.66, auc_val: 61.68\n",
      "Validation: Epoch 7,  val_loss:0.6786, aupr_val: 60.57, auc_val: 61.65\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 8,  val_loss:0.6786, aupr_val: 60.57, auc_val: 61.65\n",
      "Validation: Epoch 9,  val_loss:0.6786, aupr_val: 60.61, auc_val: 61.68\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 10,  val_loss:0.6786, aupr_val: 60.58, auc_val: 61.67\n",
      "Validation: Epoch 11,  val_loss:0.6786, aupr_val: 60.55, auc_val: 61.65\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 12,  val_loss:0.6786, aupr_val: 60.61, auc_val: 61.67\n",
      "Validation: Epoch 13,  val_loss:0.6786, aupr_val: 60.64, auc_val: 61.70\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 14,  val_loss:0.6786, aupr_val: 60.61, auc_val: 61.67\n",
      "Validation: Epoch 15,  val_loss:0.6786, aupr_val: 60.61, auc_val: 61.68\n",
      "Validation: Epoch 16,  val_loss:0.6786, aupr_val: 60.57, auc_val: 61.66\n",
      "Validation: Epoch 17,  val_loss:0.6786, aupr_val: 60.61, auc_val: 61.68\n",
      "Validation: Epoch 18,  val_loss:0.6786, aupr_val: 60.61, auc_val: 61.68\n",
      "Validation: Epoch 19,  val_loss:0.6786, aupr_val: 60.63, auc_val: 61.67\n",
      "Total Time elapsed: 0.087 mins\n",
      "     course  percentile       acc       bac       auc     auprc\n",
      "0  hwts-001          60  0.571429  0.544819  0.431641  0.457581\n",
      "Split id: 1\n",
      "4377 541 547 4377 541 547\n",
      "[1210] [151] [152]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4377, 1000, 12]) torch.Size([4377, 9]) torch.Size([4377, 1000, 1]) torch.Size([4377])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6992, aupr_val: 70.92, auc_val: 85.06\n",
      "**[S] Epoch 0, aupr_val: 70.9216, auc_val: 85.0586 **\n",
      "Validation: Epoch 1,  val_loss:0.7083, aupr_val: 70.92, auc_val: 85.06\n",
      "Validation: Epoch 2,  val_loss:0.7190, aupr_val: 70.92, auc_val: 85.06\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.7142, aupr_val: 70.92, auc_val: 85.06\n",
      "Validation: Epoch 4,  val_loss:0.7169, aupr_val: 70.92, auc_val: 85.06\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.7164, aupr_val: 70.92, auc_val: 85.06\n",
      "Validation: Epoch 6,  val_loss:0.7163, aupr_val: 70.92, auc_val: 85.06\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.7163, aupr_val: 70.92, auc_val: 85.06\n",
      "Validation: Epoch 8,  val_loss:0.7163, aupr_val: 70.92, auc_val: 85.06\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.7163, aupr_val: 70.92, auc_val: 85.06\n",
      "Validation: Epoch 10,  val_loss:0.7163, aupr_val: 70.92, auc_val: 85.06\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.7163, aupr_val: 70.92, auc_val: 85.06\n",
      "Validation: Epoch 12,  val_loss:0.7163, aupr_val: 70.92, auc_val: 85.06\n",
      "Validation: Epoch 13,  val_loss:0.7163, aupr_val: 70.92, auc_val: 85.06\n",
      "Validation: Epoch 14,  val_loss:0.7163, aupr_val: 70.92, auc_val: 85.06\n",
      "Validation: Epoch 15,  val_loss:0.7163, aupr_val: 70.92, auc_val: 85.06\n",
      "Validation: Epoch 16,  val_loss:0.7163, aupr_val: 70.92, auc_val: 85.06\n",
      "Validation: Epoch 17,  val_loss:0.7163, aupr_val: 70.92, auc_val: 85.06\n",
      "Validation: Epoch 18,  val_loss:0.7163, aupr_val: 70.92, auc_val: 85.06\n",
      "Validation: Epoch 19,  val_loss:0.7163, aupr_val: 70.92, auc_val: 85.06\n",
      "Total Time elapsed: 0.431 mins\n",
      "    course  percentile       acc       bac       auc     auprc\n",
      "0  dsp-001          40  0.297153  0.518293  0.340436  0.198627\n",
      "Split id: 1\n",
      "4432 554 551 4432 554 551\n",
      "[1210] [151] [152]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4432, 1000, 12]) torch.Size([4432, 9]) torch.Size([4432, 1000, 1]) torch.Size([4432])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6965, aupr_val: 15.73, auc_val: 7.84\n",
      "**[S] Epoch 0, aupr_val: 15.7293, auc_val: 7.8386 **\n",
      "Validation: Epoch 1,  val_loss:0.6900, aupr_val: 15.73, auc_val: 7.84\n",
      "Validation: Epoch 2,  val_loss:0.6187, aupr_val: 15.73, auc_val: 7.84\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.6099, aupr_val: 15.73, auc_val: 7.84\n",
      "Validation: Epoch 4,  val_loss:0.6056, aupr_val: 15.73, auc_val: 7.84\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.6052, aupr_val: 15.73, auc_val: 7.84\n",
      "Validation: Epoch 6,  val_loss:0.6052, aupr_val: 15.73, auc_val: 7.84\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.6051, aupr_val: 15.73, auc_val: 7.84\n",
      "Validation: Epoch 8,  val_loss:0.6050, aupr_val: 15.73, auc_val: 7.84\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.6050, aupr_val: 15.73, auc_val: 7.84\n",
      "Validation: Epoch 10,  val_loss:0.6050, aupr_val: 15.73, auc_val: 7.84\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.6050, aupr_val: 15.73, auc_val: 7.84\n",
      "Validation: Epoch 12,  val_loss:0.6050, aupr_val: 15.73, auc_val: 7.84\n",
      "Validation: Epoch 13,  val_loss:0.6050, aupr_val: 15.73, auc_val: 7.84\n",
      "Validation: Epoch 14,  val_loss:0.6050, aupr_val: 15.73, auc_val: 7.84\n",
      "Validation: Epoch 15,  val_loss:0.6050, aupr_val: 15.73, auc_val: 7.84\n",
      "Validation: Epoch 16,  val_loss:0.6050, aupr_val: 15.73, auc_val: 7.84\n",
      "Validation: Epoch 17,  val_loss:0.6050, aupr_val: 15.73, auc_val: 7.84\n",
      "Validation: Epoch 18,  val_loss:0.6050, aupr_val: 15.73, auc_val: 7.84\n",
      "Validation: Epoch 19,  val_loss:0.6050, aupr_val: 15.73, auc_val: 7.84\n",
      "Total Time elapsed: 0.437 mins\n",
      "    course  percentile       acc       bac       auc     auprc\n",
      "0  dsp-001          60  0.290036  0.513415  0.130392  0.162554\n",
      "Split id: 1\n",
      "6172 771 772 6172 771 772\n",
      "[5097] [638] [638]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6172, 1000, 24]) torch.Size([6172, 9]) torch.Size([6172, 1000, 1]) torch.Size([6172])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6862, aupr_val: 82.68, auc_val: 50.41\n",
      "**[S] Epoch 0, aupr_val: 82.6834, auc_val: 50.4137 **\n",
      "Validation: Epoch 1,  val_loss:0.6872, aupr_val: 82.48, auc_val: 50.30\n",
      "Validation: Epoch 2,  val_loss:0.6878, aupr_val: 82.49, auc_val: 50.32\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.6905, aupr_val: 82.49, auc_val: 50.32\n",
      "Validation: Epoch 4,  val_loss:0.6895, aupr_val: 82.49, auc_val: 50.32\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.6894, aupr_val: 82.49, auc_val: 50.32\n",
      "Validation: Epoch 6,  val_loss:0.6895, aupr_val: 82.49, auc_val: 50.32\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.6895, aupr_val: 82.49, auc_val: 50.32\n",
      "Validation: Epoch 8,  val_loss:0.6895, aupr_val: 82.49, auc_val: 50.32\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.6895, aupr_val: 82.49, auc_val: 50.32\n",
      "Validation: Epoch 10,  val_loss:0.6895, aupr_val: 82.49, auc_val: 50.32\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.6895, aupr_val: 82.49, auc_val: 50.32\n",
      "Validation: Epoch 12,  val_loss:0.6895, aupr_val: 82.49, auc_val: 50.32\n",
      "Validation: Epoch 13,  val_loss:0.6895, aupr_val: 82.49, auc_val: 50.32\n",
      "Validation: Epoch 14,  val_loss:0.6895, aupr_val: 82.49, auc_val: 50.32\n",
      "Validation: Epoch 15,  val_loss:0.6895, aupr_val: 82.49, auc_val: 50.32\n",
      "Validation: Epoch 16,  val_loss:0.6895, aupr_val: 82.49, auc_val: 50.32\n",
      "Validation: Epoch 17,  val_loss:0.6895, aupr_val: 82.49, auc_val: 50.32\n",
      "Validation: Epoch 18,  val_loss:0.6895, aupr_val: 82.49, auc_val: 50.32\n",
      "Validation: Epoch 19,  val_loss:0.6895, aupr_val: 82.49, auc_val: 50.32\n",
      "Total Time elapsed: 0.197 mins\n",
      "        course  percentile       acc       bac       auc     auprc\n",
      "0  progfun-002          40  0.798469  0.518181  0.527279  0.821343\n",
      "Split id: 1\n",
      "6227 777 781 6227 777 781\n",
      "[5123] [641] [641]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6227, 1000, 24]) torch.Size([6227, 9]) torch.Size([6227, 1000, 1]) torch.Size([6227])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.7017, aupr_val: 82.53, auc_val: 49.58\n",
      "**[S] Epoch 0, aupr_val: 82.5346, auc_val: 49.5767 **\n",
      "Validation: Epoch 1,  val_loss:0.6945, aupr_val: 82.75, auc_val: 49.92\n",
      "**[S] Epoch 1, aupr_val: 82.7519, auc_val: 49.9249 **\n",
      "Validation: Epoch 2,  val_loss:0.6976, aupr_val: 82.99, auc_val: 50.21\n",
      "**[S] Epoch 2, aupr_val: 82.9941, auc_val: 50.2099 **\n",
      "Validation: Epoch 3,  val_loss:0.6972, aupr_val: 82.97, auc_val: 50.16\n",
      "Validation: Epoch 4,  val_loss:0.6980, aupr_val: 83.04, auc_val: 50.22\n",
      "**[S] Epoch 4, aupr_val: 83.0390, auc_val: 50.2162 **\n",
      "Validation: Epoch 5,  val_loss:0.6980, aupr_val: 82.94, auc_val: 49.94\n",
      "Validation: Epoch 6,  val_loss:0.6966, aupr_val: 83.01, auc_val: 50.48\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n",
      "**[S] Epoch 6, aupr_val: 83.0118, auc_val: 50.4801 **\n",
      "Validation: Epoch 7,  val_loss:0.6968, aupr_val: 82.97, auc_val: 50.42\n",
      "Validation: Epoch 8,  val_loss:0.6965, aupr_val: 83.10, auc_val: 50.67\n",
      "**[S] Epoch 8, aupr_val: 83.1034, auc_val: 50.6711 **\n",
      "Validation: Epoch 9,  val_loss:0.6961, aupr_val: 83.20, auc_val: 50.83\n",
      "**[S] Epoch 9, aupr_val: 83.1976, auc_val: 50.8311 **\n",
      "Validation: Epoch 10,  val_loss:0.6957, aupr_val: 82.93, auc_val: 50.18\n",
      "Validation: Epoch 11,  val_loss:0.6964, aupr_val: 82.90, auc_val: 50.17\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 12,  val_loss:0.6964, aupr_val: 82.90, auc_val: 50.16\n",
      "Validation: Epoch 13,  val_loss:0.6965, aupr_val: 82.92, auc_val: 50.17\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 14,  val_loss:0.6965, aupr_val: 82.92, auc_val: 50.17\n",
      "Validation: Epoch 15,  val_loss:0.6965, aupr_val: 82.91, auc_val: 50.17\n",
      "Epoch 00016: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 16,  val_loss:0.6965, aupr_val: 82.91, auc_val: 50.17\n",
      "Validation: Epoch 17,  val_loss:0.6965, aupr_val: 82.91, auc_val: 50.17\n",
      "Epoch 00018: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 18,  val_loss:0.6965, aupr_val: 82.91, auc_val: 50.17\n",
      "Validation: Epoch 19,  val_loss:0.6965, aupr_val: 82.91, auc_val: 50.17\n",
      "Total Time elapsed: 0.162 mins\n",
      "        course  percentile       acc       bac       auc     auprc\n",
      "0  progfun-002          60  0.192602  0.495374  0.516206  0.815847\n",
      "Split id: 1\n",
      "445 56 56 445 56 56\n",
      "[222] [28] [27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([445, 1000, 26]) torch.Size([445, 9]) torch.Size([445, 1000, 1]) torch.Size([445])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6941, aupr_val: 54.58, auc_val: 54.78\n",
      "**[S] Epoch 0, aupr_val: 54.5794, auc_val: 54.7832 **\n",
      "Validation: Epoch 1,  val_loss:0.6945, aupr_val: 54.54, auc_val: 54.66\n",
      "Validation: Epoch 2,  val_loss:0.6941, aupr_val: 63.29, auc_val: 60.91\n",
      "**[S] Epoch 2, aupr_val: 63.2850, auc_val: 60.9056 **\n",
      "Validation: Epoch 3,  val_loss:0.6942, aupr_val: 62.34, auc_val: 59.76\n",
      "Validation: Epoch 4,  val_loss:0.6944, aupr_val: 57.62, auc_val: 57.72\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 5,  val_loss:0.6944, aupr_val: 58.77, auc_val: 58.10\n",
      "Validation: Epoch 6,  val_loss:0.6945, aupr_val: 58.77, auc_val: 58.10\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 7,  val_loss:0.6945, aupr_val: 58.77, auc_val: 58.10\n",
      "Validation: Epoch 8,  val_loss:0.6945, aupr_val: 58.77, auc_val: 58.10\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 9,  val_loss:0.6945, aupr_val: 58.77, auc_val: 58.10\n",
      "Validation: Epoch 10,  val_loss:0.6945, aupr_val: 58.77, auc_val: 58.10\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 11,  val_loss:0.6945, aupr_val: 58.77, auc_val: 58.10\n",
      "Validation: Epoch 12,  val_loss:0.6945, aupr_val: 58.77, auc_val: 58.10\n",
      "Epoch 00013: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 13,  val_loss:0.6945, aupr_val: 58.77, auc_val: 58.10\n",
      "Validation: Epoch 14,  val_loss:0.6945, aupr_val: 58.77, auc_val: 58.10\n",
      "Validation: Epoch 15,  val_loss:0.6945, aupr_val: 58.77, auc_val: 58.10\n",
      "Validation: Epoch 16,  val_loss:0.6945, aupr_val: 58.77, auc_val: 58.10\n",
      "Validation: Epoch 17,  val_loss:0.6945, aupr_val: 58.77, auc_val: 58.10\n",
      "Validation: Epoch 18,  val_loss:0.6945, aupr_val: 58.77, auc_val: 58.10\n",
      "Validation: Epoch 19,  val_loss:0.6945, aupr_val: 58.77, auc_val: 58.10\n",
      "Total Time elapsed: 0.031 mins\n",
      "                 course  percentile       acc       bac       auc    auprc\n",
      "0  microcontroleurs-003          40  0.473684  0.482143  0.595443  0.63421\n",
      "Split id: 1\n",
      "452 57 57 452 57 57\n",
      "[224] [28] [28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([452, 1000, 26]) torch.Size([452, 9]) torch.Size([452, 1000, 1]) torch.Size([452])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6941, aupr_val: 50.96, auc_val: 47.60\n",
      "**[S] Epoch 0, aupr_val: 50.9642, auc_val: 47.5985 **\n",
      "Validation: Epoch 1,  val_loss:0.6938, aupr_val: 50.80, auc_val: 46.98\n",
      "Validation: Epoch 2,  val_loss:0.6936, aupr_val: 50.67, auc_val: 46.49\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.6936, aupr_val: 50.61, auc_val: 46.24\n",
      "Validation: Epoch 4,  val_loss:0.6936, aupr_val: 50.61, auc_val: 46.24\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.6936, aupr_val: 50.61, auc_val: 46.24\n",
      "Validation: Epoch 6,  val_loss:0.6936, aupr_val: 50.61, auc_val: 46.24\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.6936, aupr_val: 50.61, auc_val: 46.24\n",
      "Validation: Epoch 8,  val_loss:0.6936, aupr_val: 50.61, auc_val: 46.24\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.6936, aupr_val: 50.61, auc_val: 46.24\n",
      "Validation: Epoch 10,  val_loss:0.6936, aupr_val: 50.61, auc_val: 46.24\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.6936, aupr_val: 50.61, auc_val: 46.24\n",
      "Validation: Epoch 12,  val_loss:0.6936, aupr_val: 50.61, auc_val: 46.24\n",
      "Validation: Epoch 13,  val_loss:0.6936, aupr_val: 50.61, auc_val: 46.24\n",
      "Validation: Epoch 14,  val_loss:0.6936, aupr_val: 50.61, auc_val: 46.24\n",
      "Validation: Epoch 15,  val_loss:0.6936, aupr_val: 50.61, auc_val: 46.24\n",
      "Validation: Epoch 16,  val_loss:0.6936, aupr_val: 50.61, auc_val: 46.24\n",
      "Validation: Epoch 17,  val_loss:0.6936, aupr_val: 50.61, auc_val: 46.24\n",
      "Validation: Epoch 18,  val_loss:0.6936, aupr_val: 50.61, auc_val: 46.24\n",
      "Validation: Epoch 19,  val_loss:0.6936, aupr_val: 50.61, auc_val: 46.24\n",
      "Total Time elapsed: 0.030 mins\n",
      "                 course  percentile       acc       bac       auc     auprc\n",
      "0  microcontroleurs-003          60  0.421053  0.427956  0.496305  0.560656\n",
      "Split id: 1\n",
      "356 45 43 356 45 43\n",
      "[163] [20] [21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([356, 1000, 24]) torch.Size([356, 9]) torch.Size([356, 1000, 1]) torch.Size([356])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6875, aupr_val: 50.03, auc_val: 55.70\n",
      "**[S] Epoch 0, aupr_val: 50.0283, auc_val: 55.7000 **\n",
      "Validation: Epoch 1,  val_loss:0.6913, aupr_val: 56.78, auc_val: 59.30\n",
      "**[S] Epoch 1, aupr_val: 56.7815, auc_val: 59.3000 **\n",
      "Validation: Epoch 2,  val_loss:0.6943, aupr_val: 56.78, auc_val: 59.30\n",
      "Validation: Epoch 3,  val_loss:0.6956, aupr_val: 56.78, auc_val: 59.30\n",
      "Epoch 00004: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 4,  val_loss:0.6956, aupr_val: 56.78, auc_val: 59.30\n",
      "Validation: Epoch 5,  val_loss:0.6955, aupr_val: 56.78, auc_val: 59.30\n",
      "Epoch 00006: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 6,  val_loss:0.6955, aupr_val: 56.78, auc_val: 59.30\n",
      "Validation: Epoch 7,  val_loss:0.6955, aupr_val: 56.78, auc_val: 59.30\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 8,  val_loss:0.6955, aupr_val: 56.78, auc_val: 59.30\n",
      "Validation: Epoch 9,  val_loss:0.6955, aupr_val: 56.78, auc_val: 59.30\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 10,  val_loss:0.6955, aupr_val: 56.78, auc_val: 59.30\n",
      "Validation: Epoch 11,  val_loss:0.6955, aupr_val: 56.78, auc_val: 59.30\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 12,  val_loss:0.6955, aupr_val: 56.78, auc_val: 59.30\n",
      "Validation: Epoch 13,  val_loss:0.6955, aupr_val: 56.78, auc_val: 59.30\n",
      "Validation: Epoch 14,  val_loss:0.6955, aupr_val: 56.78, auc_val: 59.30\n",
      "Validation: Epoch 15,  val_loss:0.6955, aupr_val: 56.78, auc_val: 59.30\n",
      "Validation: Epoch 16,  val_loss:0.6955, aupr_val: 56.78, auc_val: 59.30\n",
      "Validation: Epoch 17,  val_loss:0.6955, aupr_val: 56.78, auc_val: 59.30\n",
      "Validation: Epoch 18,  val_loss:0.6955, aupr_val: 56.78, auc_val: 59.30\n",
      "Validation: Epoch 19,  val_loss:0.6955, aupr_val: 56.78, auc_val: 59.30\n",
      "Total Time elapsed: 0.028 mins\n",
      "           course  percentile       acc  bac       auc     auprc\n",
      "0  geomatique-003          40  0.543478  0.5  0.594286  0.523235\n",
      "Split id: 1\n",
      "357 45 44 357 45 44\n",
      "[163] [20] [21]\n",
      "torch.Size([357, 1000, 24]) torch.Size([357, 9]) torch.Size([357, 1000, 1]) torch.Size([357])\n",
      "- - Run 1 - -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch 0,  val_loss:0.6890, aupr_val: 49.52, auc_val: 42.20\n",
      "**[S] Epoch 0, aupr_val: 49.5231, auc_val: 42.2000 **\n",
      "Validation: Epoch 1,  val_loss:0.6892, aupr_val: 50.69, auc_val: 44.20\n",
      "**[S] Epoch 1, aupr_val: 50.6874, auc_val: 44.2000 **\n",
      "Validation: Epoch 2,  val_loss:0.6888, aupr_val: 54.91, auc_val: 51.80\n",
      "**[S] Epoch 2, aupr_val: 54.9146, auc_val: 51.8000 **\n",
      "Validation: Epoch 3,  val_loss:0.6874, aupr_val: 56.19, auc_val: 53.00\n",
      "**[S] Epoch 3, aupr_val: 56.1856, auc_val: 53.0000 **\n",
      "Validation: Epoch 4,  val_loss:0.6857, aupr_val: 56.19, auc_val: 53.00\n",
      "Validation: Epoch 5,  val_loss:0.6859, aupr_val: 55.44, auc_val: 52.80\n",
      "Epoch 00006: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 6,  val_loss:0.6858, aupr_val: 55.44, auc_val: 52.80\n",
      "Validation: Epoch 7,  val_loss:0.6856, aupr_val: 55.44, auc_val: 52.80\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 8,  val_loss:0.6855, aupr_val: 55.44, auc_val: 52.80\n",
      "Validation: Epoch 9,  val_loss:0.6855, aupr_val: 55.44, auc_val: 52.80\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 10,  val_loss:0.6855, aupr_val: 55.44, auc_val: 52.80\n",
      "Validation: Epoch 11,  val_loss:0.6855, aupr_val: 55.44, auc_val: 52.80\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 12,  val_loss:0.6855, aupr_val: 55.44, auc_val: 52.80\n",
      "Validation: Epoch 13,  val_loss:0.6855, aupr_val: 55.44, auc_val: 52.80\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 14,  val_loss:0.6855, aupr_val: 55.44, auc_val: 52.80\n",
      "Validation: Epoch 15,  val_loss:0.6855, aupr_val: 55.44, auc_val: 52.80\n",
      "Validation: Epoch 16,  val_loss:0.6855, aupr_val: 55.44, auc_val: 52.80\n",
      "Validation: Epoch 17,  val_loss:0.6855, aupr_val: 55.44, auc_val: 52.80\n",
      "Validation: Epoch 18,  val_loss:0.6855, aupr_val: 55.44, auc_val: 52.80\n",
      "Validation: Epoch 19,  val_loss:0.6855, aupr_val: 55.44, auc_val: 52.80\n",
      "Total Time elapsed: 0.028 mins\n",
      "           course  percentile       acc       bac       auc     auprc\n",
      "0  geomatique-003          60  0.478261  0.451429  0.420952  0.416491\n",
      "Split id: 1\n",
      "3602 441 450 3602 441 450\n",
      "[445] [56] [56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3602, 1000, 24]) torch.Size([3602, 9]) torch.Size([3602, 1000, 1]) torch.Size([3602])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6948, aupr_val: 28.94, auc_val: 72.97\n",
      "**[S] Epoch 0, aupr_val: 28.9429, auc_val: 72.9708 **\n",
      "Validation: Epoch 1,  val_loss:0.6927, aupr_val: 28.45, auc_val: 74.61\n",
      "**[S] Epoch 1, aupr_val: 28.4492, auc_val: 74.6127 **\n",
      "Validation: Epoch 2,  val_loss:0.6805, aupr_val: 32.92, auc_val: 82.32\n",
      "**[S] Epoch 2, aupr_val: 32.9233, auc_val: 82.3214 **\n",
      "Validation: Epoch 3,  val_loss:0.6740, aupr_val: 33.58, auc_val: 83.45\n",
      "**[S] Epoch 3, aupr_val: 33.5825, auc_val: 83.4485 **\n",
      "Validation: Epoch 4,  val_loss:0.6423, aupr_val: 13.74, auc_val: 36.70\n",
      "Validation: Epoch 5,  val_loss:0.5751, aupr_val: 13.87, auc_val: 26.87\n",
      "Epoch 00006: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 6,  val_loss:0.5728, aupr_val: 13.84, auc_val: 26.86\n",
      "Validation: Epoch 7,  val_loss:0.5632, aupr_val: 13.84, auc_val: 26.86\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 8,  val_loss:0.5633, aupr_val: 13.84, auc_val: 26.86\n",
      "Validation: Epoch 9,  val_loss:0.5639, aupr_val: 13.84, auc_val: 26.86\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 10,  val_loss:0.5638, aupr_val: 13.84, auc_val: 26.86\n",
      "Validation: Epoch 11,  val_loss:0.5638, aupr_val: 13.84, auc_val: 26.86\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 12,  val_loss:0.5638, aupr_val: 13.84, auc_val: 26.86\n",
      "Validation: Epoch 13,  val_loss:0.5638, aupr_val: 13.84, auc_val: 26.86\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 14,  val_loss:0.5638, aupr_val: 13.84, auc_val: 26.86\n",
      "Validation: Epoch 15,  val_loss:0.5638, aupr_val: 13.84, auc_val: 26.86\n",
      "Validation: Epoch 16,  val_loss:0.5638, aupr_val: 13.84, auc_val: 26.86\n",
      "Validation: Epoch 17,  val_loss:0.5638, aupr_val: 13.84, auc_val: 26.86\n",
      "Validation: Epoch 18,  val_loss:0.5638, aupr_val: 13.84, auc_val: 26.86\n",
      "Validation: Epoch 19,  val_loss:0.5638, aupr_val: 13.84, auc_val: 26.86\n",
      "Total Time elapsed: 0.181 mins\n",
      "                 course  percentile       acc       bac       auc     auprc\n",
      "0  villesafricaines-001          40  0.890909  0.634701  0.492068  0.261809\n",
      "Split id: 1\n",
      "3718 457 469 3718 457 469\n",
      "[449] [56] [56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3718, 1000, 24]) torch.Size([3718, 9]) torch.Size([3718, 1000, 1]) torch.Size([3718])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6789, aupr_val: 13.87, auc_val: 30.93\n",
      "**[S] Epoch 0, aupr_val: 13.8706, auc_val: 30.9294 **\n",
      "Validation: Epoch 1,  val_loss:0.6680, aupr_val: 15.58, auc_val: 32.14\n",
      "**[S] Epoch 1, aupr_val: 15.5754, auc_val: 32.1362 **\n",
      "Validation: Epoch 2,  val_loss:0.6668, aupr_val: 16.02, auc_val: 33.28\n",
      "**[S] Epoch 2, aupr_val: 16.0199, auc_val: 33.2806 **\n",
      "Validation: Epoch 3,  val_loss:0.6277, aupr_val: 16.18, auc_val: 33.58\n",
      "**[S] Epoch 3, aupr_val: 16.1759, auc_val: 33.5835 **\n",
      "Validation: Epoch 4,  val_loss:0.6461, aupr_val: 17.35, auc_val: 33.97\n",
      "**[S] Epoch 4, aupr_val: 17.3525, auc_val: 33.9664 **\n",
      "Validation: Epoch 5,  val_loss:0.5620, aupr_val: 17.89, auc_val: 34.02\n",
      "**[S] Epoch 5, aupr_val: 17.8935, auc_val: 34.0154 **\n",
      "Validation: Epoch 6,  val_loss:0.5075, aupr_val: 17.42, auc_val: 34.02\n",
      "**[S] Epoch 6, aupr_val: 17.4233, auc_val: 34.0154 **\n",
      "Validation: Epoch 7,  val_loss:0.4785, aupr_val: 17.21, auc_val: 34.00\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 8,  val_loss:0.4820, aupr_val: 17.23, auc_val: 34.01\n",
      "Validation: Epoch 9,  val_loss:0.4809, aupr_val: 17.50, auc_val: 34.01\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 10,  val_loss:0.4806, aupr_val: 17.53, auc_val: 34.01\n",
      "Validation: Epoch 11,  val_loss:0.4799, aupr_val: 17.60, auc_val: 34.02\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 12,  val_loss:0.4799, aupr_val: 17.60, auc_val: 34.02\n",
      "Validation: Epoch 13,  val_loss:0.4799, aupr_val: 17.60, auc_val: 34.02\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 14,  val_loss:0.4799, aupr_val: 17.60, auc_val: 34.02\n",
      "Validation: Epoch 15,  val_loss:0.4798, aupr_val: 17.60, auc_val: 34.02\n",
      "Epoch 00016: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 16,  val_loss:0.4798, aupr_val: 17.60, auc_val: 34.02\n",
      "Validation: Epoch 17,  val_loss:0.4798, aupr_val: 17.60, auc_val: 34.02\n",
      "Validation: Epoch 18,  val_loss:0.4798, aupr_val: 17.60, auc_val: 34.02\n",
      "Validation: Epoch 19,  val_loss:0.4798, aupr_val: 17.60, auc_val: 34.02\n",
      "Total Time elapsed: 0.187 mins\n",
      "                 course  percentile       acc       bac      auc     auprc\n",
      "0  villesafricaines-001          60  0.888889  0.664721  0.50903  0.336491\n",
      "Split id: 1\n",
      "8386 1046 1051 8386 1046 1051\n",
      "[4508] [562] [563]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8386, 1000, 24]) torch.Size([8386, 9]) torch.Size([8386, 1000, 1]) torch.Size([8386])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6923, aupr_val: 60.95, auc_val: 56.70\n",
      "**[S] Epoch 0, aupr_val: 60.9522, auc_val: 56.6976 **\n",
      "Validation: Epoch 1,  val_loss:0.6908, aupr_val: 60.73, auc_val: 56.20\n",
      "Validation: Epoch 2,  val_loss:0.6912, aupr_val: 60.79, auc_val: 56.37\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.6911, aupr_val: 60.76, auc_val: 56.28\n",
      "Validation: Epoch 4,  val_loss:0.6909, aupr_val: 60.79, auc_val: 56.27\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.6910, aupr_val: 60.79, auc_val: 56.27\n",
      "Validation: Epoch 6,  val_loss:0.6910, aupr_val: 60.77, auc_val: 56.26\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.6910, aupr_val: 60.77, auc_val: 56.27\n",
      "Validation: Epoch 8,  val_loss:0.6910, aupr_val: 60.77, auc_val: 56.27\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.6910, aupr_val: 60.77, auc_val: 56.27\n",
      "Validation: Epoch 10,  val_loss:0.6910, aupr_val: 60.77, auc_val: 56.27\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.6910, aupr_val: 60.77, auc_val: 56.27\n",
      "Validation: Epoch 12,  val_loss:0.6910, aupr_val: 60.77, auc_val: 56.27\n",
      "Validation: Epoch 13,  val_loss:0.6910, aupr_val: 60.77, auc_val: 56.27\n",
      "Validation: Epoch 14,  val_loss:0.6910, aupr_val: 60.77, auc_val: 56.27\n",
      "Validation: Epoch 15,  val_loss:0.6910, aupr_val: 60.77, auc_val: 56.27\n",
      "Validation: Epoch 16,  val_loss:0.6910, aupr_val: 60.77, auc_val: 56.27\n",
      "Validation: Epoch 17,  val_loss:0.6910, aupr_val: 60.77, auc_val: 56.27\n",
      "Validation: Epoch 18,  val_loss:0.6910, aupr_val: 60.77, auc_val: 56.27\n",
      "Validation: Epoch 19,  val_loss:0.6910, aupr_val: 60.77, auc_val: 56.27\n",
      "Total Time elapsed: 0.539 mins\n",
      "        course  percentile       acc       bac       auc     auprc\n",
      "0  progfun-003          40  0.514259  0.529372  0.579717  0.586233\n",
      "Split id: 1\n",
      "8500 1063 1066 8500 1063 1066\n",
      "[4521] [565] [566]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8500, 1000, 24]) torch.Size([8500, 9]) torch.Size([8500, 1000, 1]) torch.Size([8500])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6806, aupr_val: 64.20, auc_val: 59.10\n",
      "**[S] Epoch 0, aupr_val: 64.2015, auc_val: 59.1003 **\n",
      "Validation: Epoch 1,  val_loss:0.6791, aupr_val: 66.12, auc_val: 59.44\n",
      "**[S] Epoch 1, aupr_val: 66.1177, auc_val: 59.4376 **\n",
      "Validation: Epoch 2,  val_loss:0.6746, aupr_val: 68.55, auc_val: 60.06\n",
      "**[S] Epoch 2, aupr_val: 68.5486, auc_val: 60.0585 **\n",
      "Validation: Epoch 3,  val_loss:0.6709, aupr_val: 69.69, auc_val: 60.54\n",
      "**[S] Epoch 3, aupr_val: 69.6890, auc_val: 60.5411 **\n",
      "Validation: Epoch 4,  val_loss:0.6686, aupr_val: 69.57, auc_val: 60.68\n",
      "**[S] Epoch 4, aupr_val: 69.5652, auc_val: 60.6783 **\n",
      "Validation: Epoch 5,  val_loss:0.6655, aupr_val: 69.57, auc_val: 60.71\n",
      "Epoch 00006: reducing learning rate of group 0 to 1.0000e-04.\n",
      "**[S] Epoch 5, aupr_val: 69.5712, auc_val: 60.7138 **\n",
      "Validation: Epoch 6,  val_loss:0.6667, aupr_val: 69.48, auc_val: 60.72\n",
      "**[S] Epoch 6, aupr_val: 69.4839, auc_val: 60.7192 **\n",
      "Validation: Epoch 7,  val_loss:0.6665, aupr_val: 69.52, auc_val: 60.74\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.0000e-05.\n",
      "**[S] Epoch 7, aupr_val: 69.5191, auc_val: 60.7437 **\n",
      "Validation: Epoch 8,  val_loss:0.6664, aupr_val: 69.52, auc_val: 60.74\n",
      "Validation: Epoch 9,  val_loss:0.6665, aupr_val: 69.52, auc_val: 60.74\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 10,  val_loss:0.6665, aupr_val: 69.52, auc_val: 60.74\n",
      "Validation: Epoch 11,  val_loss:0.6665, aupr_val: 69.52, auc_val: 60.74\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 12,  val_loss:0.6665, aupr_val: 69.52, auc_val: 60.74\n",
      "Validation: Epoch 13,  val_loss:0.6665, aupr_val: 69.52, auc_val: 60.74\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 14,  val_loss:0.6665, aupr_val: 69.52, auc_val: 60.74\n",
      "Validation: Epoch 15,  val_loss:0.6665, aupr_val: 69.52, auc_val: 60.74\n",
      "Validation: Epoch 16,  val_loss:0.6665, aupr_val: 69.52, auc_val: 60.74\n",
      "Validation: Epoch 17,  val_loss:0.6665, aupr_val: 69.52, auc_val: 60.74\n",
      "Validation: Epoch 18,  val_loss:0.6665, aupr_val: 69.52, auc_val: 60.74\n",
      "Validation: Epoch 19,  val_loss:0.6665, aupr_val: 69.52, auc_val: 60.74\n",
      "Total Time elapsed: 0.553 mins\n",
      "        course  percentile       acc       bac       auc     auprc\n",
      "0  progfun-003          60  0.590616  0.602618  0.613017  0.664926\n",
      "Split id: 1\n",
      "3047 381 385 3047 381 385\n",
      "[740] [93] [91]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3047, 1000, 24]) torch.Size([3047, 9]) torch.Size([3047, 1000, 1]) torch.Size([3047])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6694, aupr_val: 40.69, auc_val: 60.87\n",
      "**[S] Epoch 0, aupr_val: 40.6897, auc_val: 60.8666 **\n",
      "Validation: Epoch 1,  val_loss:0.6683, aupr_val: 41.97, auc_val: 61.14\n",
      "**[S] Epoch 1, aupr_val: 41.9693, auc_val: 61.1428 **\n",
      "Validation: Epoch 2,  val_loss:0.6665, aupr_val: 43.12, auc_val: 61.39\n",
      "**[S] Epoch 2, aupr_val: 43.1238, auc_val: 61.3930 **\n",
      "Validation: Epoch 3,  val_loss:0.6605, aupr_val: 45.02, auc_val: 61.90\n",
      "**[S] Epoch 3, aupr_val: 45.0161, auc_val: 61.9045 **\n",
      "Validation: Epoch 4,  val_loss:0.6525, aupr_val: 47.64, auc_val: 63.57\n",
      "**[S] Epoch 4, aupr_val: 47.6360, auc_val: 63.5697 **\n",
      "Validation: Epoch 5,  val_loss:0.6641, aupr_val: 48.53, auc_val: 64.49\n",
      "**[S] Epoch 5, aupr_val: 48.5307, auc_val: 64.4937 **\n",
      "Validation: Epoch 6,  val_loss:0.6670, aupr_val: 49.63, auc_val: 64.63\n",
      "**[S] Epoch 6, aupr_val: 49.6262, auc_val: 64.6263 **\n",
      "Validation: Epoch 7,  val_loss:0.6592, aupr_val: 50.14, auc_val: 64.66\n",
      "**[S] Epoch 7, aupr_val: 50.1429, auc_val: 64.6599 **\n",
      "Validation: Epoch 8,  val_loss:0.6533, aupr_val: 50.96, auc_val: 65.29\n",
      "**[S] Epoch 8, aupr_val: 50.9559, auc_val: 65.2871 **\n",
      "Validation: Epoch 9,  val_loss:0.6486, aupr_val: 52.52, auc_val: 68.43\n",
      "**[S] Epoch 9, aupr_val: 52.5186, auc_val: 68.4252 **\n",
      "Validation: Epoch 10,  val_loss:0.6559, aupr_val: 53.23, auc_val: 69.26\n",
      "**[S] Epoch 10, aupr_val: 53.2252, auc_val: 69.2596 **\n",
      "Validation: Epoch 11,  val_loss:0.6620, aupr_val: 52.09, auc_val: 67.22\n",
      "Validation: Epoch 12,  val_loss:0.6526, aupr_val: 53.02, auc_val: 68.70\n",
      "Epoch 00013: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 13,  val_loss:0.6549, aupr_val: 52.50, auc_val: 67.87\n",
      "Validation: Epoch 14,  val_loss:0.6532, aupr_val: 52.48, auc_val: 67.85\n",
      "Epoch 00015: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 15,  val_loss:0.6530, aupr_val: 52.51, auc_val: 67.85\n",
      "Validation: Epoch 16,  val_loss:0.6527, aupr_val: 52.49, auc_val: 67.82\n",
      "Epoch 00017: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 17,  val_loss:0.6527, aupr_val: 52.52, auc_val: 67.85\n",
      "Validation: Epoch 18,  val_loss:0.6527, aupr_val: 52.51, auc_val: 67.84\n",
      "Epoch 00019: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 19,  val_loss:0.6527, aupr_val: 52.52, auc_val: 67.85\n",
      "Total Time elapsed: 0.298 mins\n",
      "    course  percentile       acc       bac       auc     auprc\n",
      "0  dsp-002          40  0.746231  0.591521  0.612233  0.424368\n",
      "Split id: 1\n",
      "3102 390 392 3102 390 392\n",
      "[742] [93] [93]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3102, 1000, 24]) torch.Size([3102, 9]) torch.Size([3102, 1000, 1]) torch.Size([3102])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6610, aupr_val: 52.10, auc_val: 68.20\n",
      "**[S] Epoch 0, aupr_val: 52.1003, auc_val: 68.1999 **\n",
      "Validation: Epoch 1,  val_loss:0.6552, aupr_val: 55.79, auc_val: 68.63\n",
      "**[S] Epoch 1, aupr_val: 55.7935, auc_val: 68.6308 **\n",
      "Validation: Epoch 2,  val_loss:0.6431, aupr_val: 59.51, auc_val: 69.74\n",
      "**[S] Epoch 2, aupr_val: 59.5076, auc_val: 69.7404 **\n",
      "Validation: Epoch 3,  val_loss:0.6241, aupr_val: 62.24, auc_val: 72.03\n",
      "**[S] Epoch 3, aupr_val: 62.2380, auc_val: 72.0340 **\n",
      "Validation: Epoch 4,  val_loss:0.6028, aupr_val: 62.59, auc_val: 72.12\n",
      "**[S] Epoch 4, aupr_val: 62.5891, auc_val: 72.1209 **\n",
      "Validation: Epoch 5,  val_loss:0.6176, aupr_val: 63.12, auc_val: 72.49\n",
      "**[S] Epoch 5, aupr_val: 63.1228, auc_val: 72.4919 **\n",
      "Validation: Epoch 6,  val_loss:0.6119, aupr_val: 64.05, auc_val: 73.55\n",
      "**[S] Epoch 6, aupr_val: 64.0469, auc_val: 73.5455 **\n",
      "Validation: Epoch 7,  val_loss:0.6126, aupr_val: 64.21, auc_val: 73.31\n",
      "Validation: Epoch 8,  val_loss:0.5884, aupr_val: 64.62, auc_val: 73.62\n",
      "**[S] Epoch 8, aupr_val: 64.6171, auc_val: 73.6197 **\n",
      "Validation: Epoch 9,  val_loss:0.5799, aupr_val: 64.56, auc_val: 73.83\n",
      "**[S] Epoch 9, aupr_val: 64.5604, auc_val: 73.8297 **\n",
      "Validation: Epoch 10,  val_loss:0.5711, aupr_val: 64.68, auc_val: 74.05\n",
      "**[S] Epoch 10, aupr_val: 64.6791, auc_val: 74.0505 **\n",
      "Validation: Epoch 11,  val_loss:0.5712, aupr_val: 64.71, auc_val: 74.21\n",
      "**[S] Epoch 11, aupr_val: 64.7083, auc_val: 74.2080 **\n",
      "Validation: Epoch 12,  val_loss:0.5540, aupr_val: 64.46, auc_val: 73.82\n",
      "Validation: Epoch 13,  val_loss:0.5390, aupr_val: 64.26, auc_val: 73.76\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 14,  val_loss:0.5515, aupr_val: 64.05, auc_val: 73.18\n",
      "Validation: Epoch 15,  val_loss:0.5443, aupr_val: 64.41, auc_val: 73.79\n",
      "Epoch 00016: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 16,  val_loss:0.5448, aupr_val: 64.41, auc_val: 73.79\n",
      "Validation: Epoch 17,  val_loss:0.5452, aupr_val: 64.38, auc_val: 73.79\n",
      "Epoch 00018: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 18,  val_loss:0.5452, aupr_val: 64.38, auc_val: 73.79\n",
      "Validation: Epoch 19,  val_loss:0.5453, aupr_val: 64.38, auc_val: 73.78\n",
      "Epoch 00020: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Total Time elapsed: 0.297 mins\n",
      "    course  percentile       acc       bac       auc    auprc\n",
      "0  dsp-002          60  0.796482  0.669152  0.674952  0.54908\n",
      "Split id: 1\n",
      "77 10 10 77 10 10\n",
      "[65] [8] [9]\n",
      "torch.Size([77, 1000, 26]) torch.Size([77, 9]) torch.Size([77, 1000, 1]) torch.Size([77])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n",
      "**[S] Epoch 0, aupr_val: 92.9365, auc_val: 68.7500 **\n",
      "Validation: Epoch 1,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n",
      "Validation: Epoch 2,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n",
      "Validation: Epoch 4,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n",
      "Validation: Epoch 6,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n",
      "Validation: Epoch 8,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n",
      "Validation: Epoch 10,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n",
      "Validation: Epoch 12,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n",
      "Validation: Epoch 13,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n",
      "Validation: Epoch 14,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n",
      "Validation: Epoch 15,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n",
      "Validation: Epoch 16,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n",
      "Validation: Epoch 17,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch 18,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n",
      "Validation: Epoch 19,  val_loss:0.6997, aupr_val: 92.94, auc_val: 68.75\n",
      "Total Time elapsed: 0.001 mins\n",
      "           course  percentile  acc  bac       auc     auprc\n",
      "0  structures-002          40  0.1  0.5  0.111111  0.841226\n",
      "Split id: 1\n",
      "77 10 10 77 10 10\n",
      "[65] [8] [9]\n",
      "torch.Size([77, 1000, 26]) torch.Size([77, 9]) torch.Size([77, 1000, 1]) torch.Size([77])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "**[S] Epoch 0, aupr_val: 91.5972, auc_val: 65.6250 **\n",
      "Validation: Epoch 1,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "Validation: Epoch 2,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "Validation: Epoch 4,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "Validation: Epoch 6,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "Validation: Epoch 8,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "Validation: Epoch 10,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "Validation: Epoch 12,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "Validation: Epoch 13,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "Validation: Epoch 14,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "Validation: Epoch 15,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "Validation: Epoch 16,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "Validation: Epoch 17,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "Validation: Epoch 18,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "Validation: Epoch 19,  val_loss:0.6798, aupr_val: 91.60, auc_val: 65.62\n",
      "Total Time elapsed: 0.002 mins\n",
      "           course  percentile  acc       bac       auc     auprc\n",
      "0  structures-002          60  0.7  0.388889  0.111111  0.841226\n",
      "Split id: 1\n",
      "542 67 72 542 67 72\n",
      "[353] [45] [47]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([542, 1000, 26]) torch.Size([542, 9]) torch.Size([542, 1000, 1]) torch.Size([542])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6949, aupr_val: 66.36, auc_val: 45.61\n",
      "**[S] Epoch 0, aupr_val: 66.3600, auc_val: 45.6061 **\n",
      "Validation: Epoch 1,  val_loss:0.6931, aupr_val: 66.55, auc_val: 45.71\n",
      "**[S] Epoch 1, aupr_val: 66.5452, auc_val: 45.7071 **\n",
      "Validation: Epoch 2,  val_loss:0.6922, aupr_val: 66.36, auc_val: 45.61\n",
      "Validation: Epoch 3,  val_loss:0.6915, aupr_val: 66.23, auc_val: 45.51\n",
      "Epoch 00004: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 4,  val_loss:0.6915, aupr_val: 66.23, auc_val: 45.51\n",
      "Validation: Epoch 5,  val_loss:0.6915, aupr_val: 66.15, auc_val: 45.40\n",
      "Epoch 00006: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 6,  val_loss:0.6915, aupr_val: 66.15, auc_val: 45.40\n",
      "Validation: Epoch 7,  val_loss:0.6916, aupr_val: 66.15, auc_val: 45.40\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 8,  val_loss:0.6916, aupr_val: 66.15, auc_val: 45.40\n",
      "Validation: Epoch 9,  val_loss:0.6916, aupr_val: 66.15, auc_val: 45.40\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 10,  val_loss:0.6916, aupr_val: 66.15, auc_val: 45.40\n",
      "Validation: Epoch 11,  val_loss:0.6916, aupr_val: 66.15, auc_val: 45.40\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 12,  val_loss:0.6916, aupr_val: 66.15, auc_val: 45.40\n",
      "Validation: Epoch 13,  val_loss:0.6916, aupr_val: 66.15, auc_val: 45.40\n",
      "Validation: Epoch 14,  val_loss:0.6916, aupr_val: 66.15, auc_val: 45.40\n",
      "Validation: Epoch 15,  val_loss:0.6916, aupr_val: 66.15, auc_val: 45.40\n",
      "Validation: Epoch 16,  val_loss:0.6916, aupr_val: 66.15, auc_val: 45.40\n",
      "Validation: Epoch 17,  val_loss:0.6916, aupr_val: 66.15, auc_val: 45.40\n",
      "Validation: Epoch 18,  val_loss:0.6916, aupr_val: 66.15, auc_val: 45.40\n",
      "Validation: Epoch 19,  val_loss:0.6916, aupr_val: 66.15, auc_val: 45.40\n",
      "Total Time elapsed: 0.022 mins\n",
      "            course  percentile       acc       bac       auc     auprc\n",
      "0  initprogcpp-001          40  0.410959  0.473813  0.494272  0.612475\n",
      "Split id: 1\n",
      "576 70 73 576 70 73\n",
      "[367] [46] [47]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([576, 1000, 26]) torch.Size([576, 9]) torch.Size([576, 1000, 1]) torch.Size([576])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6928, aupr_val: 66.52, auc_val: 51.68\n",
      "**[S] Epoch 0, aupr_val: 66.5204, auc_val: 51.6757 **\n",
      "Validation: Epoch 1,  val_loss:0.6968, aupr_val: 67.50, auc_val: 54.03\n",
      "**[S] Epoch 1, aupr_val: 67.4992, auc_val: 54.0308 **\n",
      "Validation: Epoch 2,  val_loss:0.6962, aupr_val: 67.31, auc_val: 54.03\n",
      "Validation: Epoch 3,  val_loss:0.6939, aupr_val: 69.77, auc_val: 56.39\n",
      "**[S] Epoch 3, aupr_val: 69.7679, auc_val: 56.3859 **\n",
      "Validation: Epoch 4,  val_loss:0.6921, aupr_val: 70.80, auc_val: 57.29\n",
      "**[S] Epoch 4, aupr_val: 70.7955, auc_val: 57.2917 **\n",
      "Validation: Epoch 5,  val_loss:0.6918, aupr_val: 70.73, auc_val: 57.29\n",
      "**[S] Epoch 5, aupr_val: 70.7275, auc_val: 57.2917 **\n",
      "Validation: Epoch 6,  val_loss:0.6931, aupr_val: 68.19, auc_val: 53.03\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 7,  val_loss:0.6934, aupr_val: 68.84, auc_val: 54.30\n",
      "Validation: Epoch 8,  val_loss:0.6937, aupr_val: 68.78, auc_val: 54.48\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 9,  val_loss:0.6938, aupr_val: 68.83, auc_val: 54.66\n",
      "Validation: Epoch 10,  val_loss:0.6938, aupr_val: 68.83, auc_val: 54.66\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 11,  val_loss:0.6938, aupr_val: 68.83, auc_val: 54.71\n",
      "Validation: Epoch 12,  val_loss:0.6938, aupr_val: 68.83, auc_val: 54.66\n",
      "Epoch 00013: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 13,  val_loss:0.6938, aupr_val: 68.83, auc_val: 54.66\n",
      "Validation: Epoch 14,  val_loss:0.6938, aupr_val: 68.83, auc_val: 54.66\n",
      "Epoch 00015: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 15,  val_loss:0.6938, aupr_val: 68.83, auc_val: 54.66\n",
      "Validation: Epoch 16,  val_loss:0.6938, aupr_val: 68.83, auc_val: 54.66\n",
      "Validation: Epoch 17,  val_loss:0.6938, aupr_val: 68.83, auc_val: 54.66\n",
      "Validation: Epoch 18,  val_loss:0.6938, aupr_val: 68.83, auc_val: 54.66\n",
      "Validation: Epoch 19,  val_loss:0.6938, aupr_val: 68.83, auc_val: 54.66\n",
      "Total Time elapsed: 0.032 mins\n",
      "            course  percentile       acc       bac       auc     auprc\n",
      "0  initprogcpp-001          60  0.643836  0.508592  0.453355  0.638433\n",
      "Split id: 1\n",
      "360 45 46 360 45 46\n",
      "[273] [34] [35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([360, 1000, 12]) torch.Size([360, 9]) torch.Size([360, 1000, 1]) torch.Size([360])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6819, aupr_val: 98.65, auc_val: 96.39\n",
      "**[S] Epoch 0, aupr_val: 98.6493, auc_val: 96.3904 **\n",
      "Validation: Epoch 1,  val_loss:0.6883, aupr_val: 56.80, auc_val: 3.61\n",
      "Validation: Epoch 2,  val_loss:0.6933, aupr_val: 56.80, auc_val: 3.61\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.6937, aupr_val: 56.80, auc_val: 3.61\n",
      "Validation: Epoch 4,  val_loss:0.6939, aupr_val: 56.80, auc_val: 3.61\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.6939, aupr_val: 56.80, auc_val: 3.61\n",
      "Validation: Epoch 6,  val_loss:0.6939, aupr_val: 56.80, auc_val: 3.61\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.6939, aupr_val: 56.80, auc_val: 3.61\n",
      "Validation: Epoch 8,  val_loss:0.6939, aupr_val: 56.80, auc_val: 3.61\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.6939, aupr_val: 56.80, auc_val: 3.61\n",
      "Validation: Epoch 10,  val_loss:0.6939, aupr_val: 56.80, auc_val: 3.61\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.6939, aupr_val: 56.80, auc_val: 3.61\n",
      "Validation: Epoch 12,  val_loss:0.6939, aupr_val: 56.80, auc_val: 3.61\n",
      "Validation: Epoch 13,  val_loss:0.6939, aupr_val: 56.80, auc_val: 3.61\n",
      "Validation: Epoch 14,  val_loss:0.6939, aupr_val: 56.80, auc_val: 3.61\n",
      "Validation: Epoch 15,  val_loss:0.6939, aupr_val: 56.80, auc_val: 3.61\n",
      "Validation: Epoch 16,  val_loss:0.6939, aupr_val: 56.80, auc_val: 3.61\n",
      "Validation: Epoch 17,  val_loss:0.6939, aupr_val: 56.80, auc_val: 3.61\n",
      "Validation: Epoch 18,  val_loss:0.6939, aupr_val: 56.80, auc_val: 3.61\n",
      "Validation: Epoch 19,  val_loss:0.6939, aupr_val: 56.80, auc_val: 3.61\n",
      "Total Time elapsed: 0.013 mins\n",
      "                 course  percentile      acc  bac       auc     auprc\n",
      "0  analysenumerique-003          40  0.76087  0.5  0.923377  0.975443\n",
      "Split id: 1\n",
      "362 45 46 362 45 46\n",
      "[274] [34] [35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([362, 1000, 12]) torch.Size([362, 9]) torch.Size([362, 1000, 1]) torch.Size([362])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.7333, aupr_val: 56.82, auc_val: 3.74\n",
      "**[S] Epoch 0, aupr_val: 56.8171, auc_val: 3.7433 **\n",
      "Validation: Epoch 1,  val_loss:0.7268, aupr_val: 56.82, auc_val: 3.74\n",
      "Validation: Epoch 2,  val_loss:0.7203, aupr_val: 56.82, auc_val: 3.74\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.7196, aupr_val: 56.82, auc_val: 3.74\n",
      "Validation: Epoch 4,  val_loss:0.7190, aupr_val: 56.82, auc_val: 3.74\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.7189, aupr_val: 56.82, auc_val: 3.74\n",
      "Validation: Epoch 6,  val_loss:0.7189, aupr_val: 56.82, auc_val: 3.74\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.7189, aupr_val: 56.82, auc_val: 3.74\n",
      "Validation: Epoch 8,  val_loss:0.7189, aupr_val: 56.82, auc_val: 3.74\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.7189, aupr_val: 56.82, auc_val: 3.74\n",
      "Validation: Epoch 10,  val_loss:0.7189, aupr_val: 56.82, auc_val: 3.74\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.7189, aupr_val: 56.82, auc_val: 3.74\n",
      "Validation: Epoch 12,  val_loss:0.7189, aupr_val: 56.82, auc_val: 3.74\n",
      "Validation: Epoch 13,  val_loss:0.7189, aupr_val: 56.82, auc_val: 3.74\n",
      "Validation: Epoch 14,  val_loss:0.7189, aupr_val: 56.82, auc_val: 3.74\n",
      "Validation: Epoch 15,  val_loss:0.7189, aupr_val: 56.82, auc_val: 3.74\n",
      "Validation: Epoch 16,  val_loss:0.7189, aupr_val: 56.82, auc_val: 3.74\n",
      "Validation: Epoch 17,  val_loss:0.7189, aupr_val: 56.82, auc_val: 3.74\n",
      "Validation: Epoch 18,  val_loss:0.7189, aupr_val: 56.82, auc_val: 3.74\n",
      "Validation: Epoch 19,  val_loss:0.7189, aupr_val: 56.82, auc_val: 3.74\n",
      "Total Time elapsed: 0.011 mins\n",
      "                 course  percentile      acc  bac       auc     auprc\n",
      "0  analysenumerique-003          60  0.23913  0.5  0.031169  0.568384\n",
      "Split id: 1\n",
      "840 109 102 840 109 102\n",
      "[122] [16] [14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([840, 1000, 26]) torch.Size([840, 9]) torch.Size([840, 1000, 1]) torch.Size([840])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.7020, aupr_val: 23.19, auc_val: 44.42\n",
      "**[S] Epoch 0, aupr_val: 23.1870, auc_val: 44.4220 **\n",
      "Validation: Epoch 1,  val_loss:0.6916, aupr_val: 23.29, auc_val: 45.16\n",
      "**[S] Epoch 1, aupr_val: 23.2893, auc_val: 45.1613 **\n",
      "Validation: Epoch 2,  val_loss:0.6880, aupr_val: 23.35, auc_val: 45.50\n",
      "**[S] Epoch 2, aupr_val: 23.3481, auc_val: 45.4973 **\n",
      "Validation: Epoch 3,  val_loss:0.6928, aupr_val: 23.35, auc_val: 45.56\n",
      "**[S] Epoch 3, aupr_val: 23.3520, auc_val: 45.5645 **\n",
      "Validation: Epoch 4,  val_loss:0.6963, aupr_val: 23.35, auc_val: 45.56\n",
      "Validation: Epoch 5,  val_loss:0.6948, aupr_val: 23.39, auc_val: 45.83\n",
      "**[S] Epoch 5, aupr_val: 23.3937, auc_val: 45.8333 **\n",
      "Validation: Epoch 6,  val_loss:0.6900, aupr_val: 23.58, auc_val: 46.84\n",
      "**[S] Epoch 6, aupr_val: 23.5790, auc_val: 46.8414 **\n",
      "Validation: Epoch 7,  val_loss:0.6890, aupr_val: 26.40, auc_val: 50.81\n",
      "**[S] Epoch 7, aupr_val: 26.3996, auc_val: 50.8065 **\n",
      "Validation: Epoch 8,  val_loss:0.6959, aupr_val: 23.85, auc_val: 47.92\n",
      "Validation: Epoch 9,  val_loss:0.6902, aupr_val: 30.89, auc_val: 52.55\n",
      "**[S] Epoch 9, aupr_val: 30.8875, auc_val: 52.5538 **\n",
      "Validation: Epoch 10,  val_loss:0.6909, aupr_val: 37.02, auc_val: 55.04\n",
      "**[S] Epoch 10, aupr_val: 37.0231, auc_val: 55.0403 **\n",
      "Validation: Epoch 11,  val_loss:0.6944, aupr_val: 37.02, auc_val: 55.04\n",
      "Validation: Epoch 12,  val_loss:0.6883, aupr_val: 37.02, auc_val: 55.04\n",
      "Epoch 00013: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 13,  val_loss:0.6876, aupr_val: 37.02, auc_val: 55.04\n",
      "Validation: Epoch 14,  val_loss:0.6885, aupr_val: 37.02, auc_val: 55.04\n",
      "Epoch 00015: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 15,  val_loss:0.6887, aupr_val: 37.02, auc_val: 55.04\n",
      "Validation: Epoch 16,  val_loss:0.6889, aupr_val: 37.02, auc_val: 55.04\n",
      "Epoch 00017: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 17,  val_loss:0.6889, aupr_val: 37.02, auc_val: 55.04\n",
      "Validation: Epoch 18,  val_loss:0.6889, aupr_val: 37.02, auc_val: 55.04\n",
      "Epoch 00019: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 19,  val_loss:0.6889, aupr_val: 37.02, auc_val: 55.04\n",
      "Total Time elapsed: 0.051 mins\n",
      "                 course  percentile       acc  bac      auc     auprc\n",
      "0  microcontroleurs-006          40  0.891156  0.5  0.52958  0.116709\n",
      "Split id: 1\n",
      "971 123 127 971 123 127\n",
      "[127] [16] [16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([971, 1000, 26]) torch.Size([971, 9]) torch.Size([971, 1000, 1]) torch.Size([971])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.7038, aupr_val: 21.12, auc_val: 44.42\n",
      "**[S] Epoch 0, aupr_val: 21.1238, auc_val: 44.4217 **\n",
      "Validation: Epoch 1,  val_loss:0.7003, aupr_val: 21.18, auc_val: 45.01\n",
      "**[S] Epoch 1, aupr_val: 21.1837, auc_val: 45.0058 **\n",
      "Validation: Epoch 2,  val_loss:0.6925, aupr_val: 21.59, auc_val: 48.22\n",
      "**[S] Epoch 2, aupr_val: 21.5871, auc_val: 48.2185 **\n",
      "Validation: Epoch 3,  val_loss:0.6975, aupr_val: 21.73, auc_val: 49.09\n",
      "**[S] Epoch 3, aupr_val: 21.7277, auc_val: 49.0946 **\n",
      "Validation: Epoch 4,  val_loss:0.6996, aupr_val: 22.82, auc_val: 53.94\n",
      "**[S] Epoch 4, aupr_val: 22.8227, auc_val: 53.9428 **\n",
      "Validation: Epoch 5,  val_loss:0.6935, aupr_val: 49.05, auc_val: 69.25\n",
      "**[S] Epoch 5, aupr_val: 49.0518, auc_val: 69.2465 **\n",
      "Validation: Epoch 6,  val_loss:0.6915, aupr_val: 49.05, auc_val: 69.25\n",
      "Validation: Epoch 7,  val_loss:0.6943, aupr_val: 49.05, auc_val: 69.25\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 8,  val_loss:0.6942, aupr_val: 49.05, auc_val: 69.25\n",
      "Validation: Epoch 9,  val_loss:0.6939, aupr_val: 49.05, auc_val: 69.25\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 10,  val_loss:0.6938, aupr_val: 49.05, auc_val: 69.25\n",
      "Validation: Epoch 11,  val_loss:0.6938, aupr_val: 49.05, auc_val: 69.25\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 12,  val_loss:0.6938, aupr_val: 49.05, auc_val: 69.25\n",
      "Validation: Epoch 13,  val_loss:0.6938, aupr_val: 49.05, auc_val: 69.25\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 14,  val_loss:0.6938, aupr_val: 49.05, auc_val: 69.25\n",
      "Validation: Epoch 15,  val_loss:0.6938, aupr_val: 49.05, auc_val: 69.25\n",
      "Epoch 00016: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 16,  val_loss:0.6938, aupr_val: 49.05, auc_val: 69.25\n",
      "Validation: Epoch 17,  val_loss:0.6938, aupr_val: 49.05, auc_val: 69.25\n",
      "Validation: Epoch 18,  val_loss:0.6938, aupr_val: 49.05, auc_val: 69.25\n",
      "Validation: Epoch 19,  val_loss:0.6938, aupr_val: 49.05, auc_val: 69.25\n",
      "Total Time elapsed: 0.053 mins\n",
      "                 course  percentile       acc       bac      auc    auprc\n",
      "0  microcontroleurs-006          60  0.346939  0.633588  0.74833  0.36672\n",
      "Split id: 1\n",
      "2001 253 255 2001 253 255\n",
      "[358] [44] [45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2001, 1000, 24]) torch.Size([2001, 9]) torch.Size([2001, 1000, 1]) torch.Size([2001])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6875, aupr_val: 17.00, auc_val: 33.94\n",
      "**[S] Epoch 0, aupr_val: 17.0044, auc_val: 33.9441 **\n",
      "Validation: Epoch 1,  val_loss:0.6864, aupr_val: 16.86, auc_val: 33.95\n",
      "**[S] Epoch 1, aupr_val: 16.8637, auc_val: 33.9550 **\n",
      "Validation: Epoch 2,  val_loss:0.6783, aupr_val: 16.56, auc_val: 33.85\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.6734, aupr_val: 16.26, auc_val: 33.80\n",
      "Validation: Epoch 4,  val_loss:0.6715, aupr_val: 16.22, auc_val: 33.79\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.6716, aupr_val: 16.22, auc_val: 33.79\n",
      "Validation: Epoch 6,  val_loss:0.6717, aupr_val: 16.22, auc_val: 33.79\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.6717, aupr_val: 16.22, auc_val: 33.79\n",
      "Validation: Epoch 8,  val_loss:0.6718, aupr_val: 16.22, auc_val: 33.79\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.6718, aupr_val: 16.22, auc_val: 33.79\n",
      "Validation: Epoch 10,  val_loss:0.6718, aupr_val: 16.22, auc_val: 33.79\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.6718, aupr_val: 16.22, auc_val: 33.79\n",
      "Validation: Epoch 12,  val_loss:0.6718, aupr_val: 16.22, auc_val: 33.79\n",
      "Validation: Epoch 13,  val_loss:0.6718, aupr_val: 16.22, auc_val: 33.79\n",
      "Validation: Epoch 14,  val_loss:0.6718, aupr_val: 16.22, auc_val: 33.79\n",
      "Validation: Epoch 15,  val_loss:0.6718, aupr_val: 16.22, auc_val: 33.79\n",
      "Validation: Epoch 16,  val_loss:0.6718, aupr_val: 16.22, auc_val: 33.79\n",
      "Validation: Epoch 17,  val_loss:0.6718, aupr_val: 16.22, auc_val: 33.79\n",
      "Validation: Epoch 18,  val_loss:0.6718, aupr_val: 16.22, auc_val: 33.79\n",
      "Validation: Epoch 19,  val_loss:0.6718, aupr_val: 16.22, auc_val: 33.79\n",
      "Total Time elapsed: 0.143 mins\n",
      "    course  percentile       acc       bac       auc     auprc\n",
      "0  dsp-005          40  0.827586  0.596759  0.491461  0.291403\n",
      "Split id: 1\n",
      "2042 258 259 2042 258 259\n",
      "[358] [44] [45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2042, 1000, 24]) torch.Size([2042, 9]) torch.Size([2042, 1000, 1]) torch.Size([2042])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6648, aupr_val: 26.82, auc_val: 50.88\n",
      "**[S] Epoch 0, aupr_val: 26.8246, auc_val: 50.8762 **\n",
      "Validation: Epoch 1,  val_loss:0.6483, aupr_val: 28.12, auc_val: 51.06\n",
      "**[S] Epoch 1, aupr_val: 28.1191, auc_val: 51.0567 **\n",
      "Validation: Epoch 2,  val_loss:0.6398, aupr_val: 28.31, auc_val: 51.12\n",
      "**[S] Epoch 2, aupr_val: 28.3084, auc_val: 51.1204 **\n",
      "Validation: Epoch 3,  val_loss:0.6329, aupr_val: 27.90, auc_val: 51.12\n",
      "**[S] Epoch 3, aupr_val: 27.9003, auc_val: 51.1204 **\n",
      "Validation: Epoch 4,  val_loss:0.6535, aupr_val: 28.37, auc_val: 51.16\n",
      "**[S] Epoch 4, aupr_val: 28.3707, auc_val: 51.1629 **\n",
      "Validation: Epoch 5,  val_loss:0.6495, aupr_val: 29.30, auc_val: 51.23\n",
      "**[S] Epoch 5, aupr_val: 29.3005, auc_val: 51.2266 **\n",
      "Validation: Epoch 6,  val_loss:0.6418, aupr_val: 30.05, auc_val: 51.29\n",
      "**[S] Epoch 6, aupr_val: 30.0514, auc_val: 51.2904 **\n",
      "Validation: Epoch 7,  val_loss:0.6274, aupr_val: 30.71, auc_val: 51.36\n",
      "**[S] Epoch 7, aupr_val: 30.7135, auc_val: 51.3647 **\n",
      "Validation: Epoch 8,  val_loss:0.6270, aupr_val: 31.96, auc_val: 51.49\n",
      "**[S] Epoch 8, aupr_val: 31.9564, auc_val: 51.4921 **\n",
      "Validation: Epoch 9,  val_loss:0.6298, aupr_val: 32.48, auc_val: 51.61\n",
      "**[S] Epoch 9, aupr_val: 32.4812, auc_val: 51.6090 **\n",
      "Validation: Epoch 10,  val_loss:0.6271, aupr_val: 32.74, auc_val: 51.62\n",
      "**[S] Epoch 10, aupr_val: 32.7418, auc_val: 51.6196 **\n",
      "Validation: Epoch 11,  val_loss:0.6165, aupr_val: 37.36, auc_val: 51.82\n",
      "**[S] Epoch 11, aupr_val: 37.3610, auc_val: 51.8214 **\n",
      "Validation: Epoch 12,  val_loss:0.6215, aupr_val: 37.97, auc_val: 51.94\n",
      "**[S] Epoch 12, aupr_val: 37.9740, auc_val: 51.9382 **\n",
      "Validation: Epoch 13,  val_loss:0.5974, aupr_val: 38.67, auc_val: 52.07\n",
      "**[S] Epoch 13, aupr_val: 38.6707, auc_val: 52.0656 **\n",
      "Validation: Epoch 14,  val_loss:0.5904, aupr_val: 39.19, auc_val: 52.16\n",
      "**[S] Epoch 14, aupr_val: 39.1857, auc_val: 52.1612 **\n",
      "Validation: Epoch 15,  val_loss:0.5774, aupr_val: 39.66, auc_val: 52.28\n",
      "**[S] Epoch 15, aupr_val: 39.6631, auc_val: 52.2780 **\n",
      "Validation: Epoch 16,  val_loss:0.5714, aupr_val: 39.10, auc_val: 52.20\n",
      "Validation: Epoch 17,  val_loss:0.5602, aupr_val: 39.85, auc_val: 52.45\n",
      "**[S] Epoch 17, aupr_val: 39.8450, auc_val: 52.4480 **\n",
      "Validation: Epoch 18,  val_loss:0.5545, aupr_val: 40.02, auc_val: 52.63\n",
      "**[S] Epoch 18, aupr_val: 40.0240, auc_val: 52.6285 **\n",
      "Validation: Epoch 19,  val_loss:0.5520, aupr_val: 40.01, auc_val: 52.60\n",
      "Total Time elapsed: 0.142 mins\n",
      "    course  percentile       acc      bac       auc     auprc\n",
      "0  dsp-005          60  0.850575  0.65463  0.513066  0.396764\n",
      "Split id: 1\n",
      "749 91 96 749 91 96\n",
      "[386] [47] [51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([749, 1000, 24]) torch.Size([749, 9]) torch.Size([749, 1000, 1]) torch.Size([749])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6925, aupr_val: 74.25, auc_val: 67.99\n",
      "**[S] Epoch 0, aupr_val: 74.2459, auc_val: 67.9884 **\n",
      "Validation: Epoch 1,  val_loss:0.6931, aupr_val: 74.18, auc_val: 67.79\n",
      "Validation: Epoch 2,  val_loss:0.6924, aupr_val: 74.72, auc_val: 68.71\n",
      "**[S] Epoch 2, aupr_val: 74.7247, auc_val: 68.7137 **\n",
      "Validation: Epoch 3,  val_loss:0.6922, aupr_val: 74.14, auc_val: 67.75\n",
      "Validation: Epoch 4,  val_loss:0.6925, aupr_val: 74.29, auc_val: 68.04\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 5,  val_loss:0.6925, aupr_val: 74.32, auc_val: 68.09\n",
      "Validation: Epoch 6,  val_loss:0.6924, aupr_val: 74.29, auc_val: 68.04\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 7,  val_loss:0.6924, aupr_val: 74.29, auc_val: 68.04\n",
      "Validation: Epoch 8,  val_loss:0.6924, aupr_val: 74.29, auc_val: 68.04\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 9,  val_loss:0.6924, aupr_val: 74.29, auc_val: 68.04\n",
      "Validation: Epoch 10,  val_loss:0.6924, aupr_val: 74.29, auc_val: 68.04\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 11,  val_loss:0.6924, aupr_val: 74.29, auc_val: 68.04\n",
      "Validation: Epoch 12,  val_loss:0.6924, aupr_val: 74.29, auc_val: 68.04\n",
      "Epoch 00013: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 13,  val_loss:0.6924, aupr_val: 74.29, auc_val: 68.04\n",
      "Validation: Epoch 14,  val_loss:0.6924, aupr_val: 74.29, auc_val: 68.04\n",
      "Validation: Epoch 15,  val_loss:0.6924, aupr_val: 74.29, auc_val: 68.04\n",
      "Validation: Epoch 16,  val_loss:0.6924, aupr_val: 74.29, auc_val: 68.04\n",
      "Validation: Epoch 17,  val_loss:0.6924, aupr_val: 74.29, auc_val: 68.04\n",
      "Validation: Epoch 18,  val_loss:0.6924, aupr_val: 74.29, auc_val: 68.04\n",
      "Validation: Epoch 19,  val_loss:0.6924, aupr_val: 74.29, auc_val: 68.04\n",
      "Total Time elapsed: 0.044 mins\n",
      "     course  percentile       acc       bac       auc    auprc\n",
      "0  hwts-002          40  0.601942  0.605392  0.626131  0.59949\n",
      "Split id: 1\n",
      "790 97 100 790 97 100\n",
      "[401] [50] [51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([790, 1000, 24]) torch.Size([790, 9]) torch.Size([790, 1000, 1]) torch.Size([790])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6932, aupr_val: 67.53, auc_val: 60.30\n",
      "**[S] Epoch 0, aupr_val: 67.5267, auc_val: 60.2979 **\n",
      "Validation: Epoch 1,  val_loss:0.6921, aupr_val: 74.57, auc_val: 68.72\n",
      "**[S] Epoch 1, aupr_val: 74.5700, auc_val: 68.7234 **\n",
      "Validation: Epoch 2,  val_loss:0.6920, aupr_val: 70.98, auc_val: 68.85\n",
      "**[S] Epoch 2, aupr_val: 70.9847, auc_val: 68.8511 **\n",
      "Validation: Epoch 3,  val_loss:0.6919, aupr_val: 72.58, auc_val: 71.30\n",
      "Epoch 00004: reducing learning rate of group 0 to 1.0000e-04.\n",
      "**[S] Epoch 3, aupr_val: 72.5772, auc_val: 71.2979 **\n",
      "Validation: Epoch 4,  val_loss:0.6918, aupr_val: 72.62, auc_val: 71.28\n",
      "Validation: Epoch 5,  val_loss:0.6917, aupr_val: 72.58, auc_val: 71.30\n",
      "Epoch 00006: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 6,  val_loss:0.6916, aupr_val: 72.58, auc_val: 71.28\n",
      "Validation: Epoch 7,  val_loss:0.6916, aupr_val: 72.57, auc_val: 71.30\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 8,  val_loss:0.6916, aupr_val: 72.58, auc_val: 71.28\n",
      "Validation: Epoch 9,  val_loss:0.6916, aupr_val: 72.62, auc_val: 71.28\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 10,  val_loss:0.6916, aupr_val: 72.58, auc_val: 71.28\n",
      "Validation: Epoch 11,  val_loss:0.6916, aupr_val: 72.66, auc_val: 71.32\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-08.\n",
      "**[S] Epoch 11, aupr_val: 72.6614, auc_val: 71.3191 **\n",
      "Validation: Epoch 12,  val_loss:0.6916, aupr_val: 72.66, auc_val: 71.32\n",
      "Validation: Epoch 13,  val_loss:0.6916, aupr_val: 72.57, auc_val: 71.30\n",
      "Validation: Epoch 14,  val_loss:0.6916, aupr_val: 72.57, auc_val: 71.28\n",
      "Validation: Epoch 15,  val_loss:0.6916, aupr_val: 72.57, auc_val: 71.28\n",
      "Validation: Epoch 16,  val_loss:0.6916, aupr_val: 72.57, auc_val: 71.28\n",
      "Validation: Epoch 17,  val_loss:0.6916, aupr_val: 72.57, auc_val: 71.28\n",
      "Validation: Epoch 18,  val_loss:0.6916, aupr_val: 72.62, auc_val: 71.30\n",
      "Validation: Epoch 19,  val_loss:0.6916, aupr_val: 72.57, auc_val: 71.30\n",
      "Total Time elapsed: 0.054 mins\n",
      "     course  percentile       acc       bac       auc     auprc\n",
      "0  hwts-002          60  0.543689  0.539781  0.593891  0.563612\n",
      "Split id: 1\n",
      "1096 134 137 1096 134 137\n",
      "[282] [35] [36]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1096, 1000, 24]) torch.Size([1096, 9]) torch.Size([1096, 1000, 1]) torch.Size([1096])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6714, aupr_val: 53.97, auc_val: 74.89\n",
      "**[S] Epoch 0, aupr_val: 53.9669, auc_val: 74.8918 **\n",
      "Validation: Epoch 1,  val_loss:0.6624, aupr_val: 54.11, auc_val: 74.46\n",
      "Validation: Epoch 2,  val_loss:0.6668, aupr_val: 52.41, auc_val: 73.97\n",
      "Validation: Epoch 3,  val_loss:0.6507, aupr_val: 52.53, auc_val: 73.85\n",
      "Epoch 00004: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 4,  val_loss:0.6517, aupr_val: 52.51, auc_val: 73.80\n",
      "Validation: Epoch 5,  val_loss:0.6552, aupr_val: 52.95, auc_val: 73.91\n",
      "Epoch 00006: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 6,  val_loss:0.6553, aupr_val: 52.95, auc_val: 73.91\n",
      "Validation: Epoch 7,  val_loss:0.6550, aupr_val: 52.95, auc_val: 73.91\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 8,  val_loss:0.6550, aupr_val: 52.95, auc_val: 73.91\n",
      "Validation: Epoch 9,  val_loss:0.6550, aupr_val: 52.95, auc_val: 73.91\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 10,  val_loss:0.6550, aupr_val: 52.95, auc_val: 73.91\n",
      "Validation: Epoch 11,  val_loss:0.6550, aupr_val: 52.95, auc_val: 73.91\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 12,  val_loss:0.6550, aupr_val: 52.95, auc_val: 73.91\n",
      "Validation: Epoch 13,  val_loss:0.6550, aupr_val: 52.95, auc_val: 73.91\n",
      "Validation: Epoch 14,  val_loss:0.6550, aupr_val: 52.95, auc_val: 73.91\n",
      "Validation: Epoch 15,  val_loss:0.6550, aupr_val: 52.95, auc_val: 73.91\n",
      "Validation: Epoch 16,  val_loss:0.6550, aupr_val: 52.95, auc_val: 73.91\n",
      "Validation: Epoch 17,  val_loss:0.6550, aupr_val: 52.95, auc_val: 73.91\n",
      "Validation: Epoch 18,  val_loss:0.6550, aupr_val: 52.95, auc_val: 73.91\n",
      "Validation: Epoch 19,  val_loss:0.6550, aupr_val: 52.95, auc_val: 73.91\n",
      "Total Time elapsed: 0.106 mins\n",
      "    course  percentile       acc      bac       auc     auprc\n",
      "0  dsp-006          40  0.755102  0.65015  0.684059  0.500678\n",
      "Split id: 1\n",
      "1131 142 142 1131 142 142\n",
      "[282] [35] [36]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1131, 1000, 26]) torch.Size([1131, 9]) torch.Size([1131, 1000, 1]) torch.Size([1131])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6564, aupr_val: 54.29, auc_val: 77.45\n",
      "**[S] Epoch 0, aupr_val: 54.2938, auc_val: 77.4499 **\n",
      "Validation: Epoch 1,  val_loss:0.6367, aupr_val: 53.51, auc_val: 76.86\n",
      "Validation: Epoch 2,  val_loss:0.6301, aupr_val: 55.30, auc_val: 77.18\n",
      "Validation: Epoch 3,  val_loss:0.6361, aupr_val: 57.25, auc_val: 77.72\n",
      "**[S] Epoch 3, aupr_val: 57.2473, auc_val: 77.7170 **\n",
      "Validation: Epoch 4,  val_loss:0.6331, aupr_val: 61.54, auc_val: 78.54\n",
      "**[S] Epoch 4, aupr_val: 61.5351, auc_val: 78.5447 **\n",
      "Validation: Epoch 5,  val_loss:0.6305, aupr_val: 66.16, auc_val: 79.35\n",
      "**[S] Epoch 5, aupr_val: 66.1603, auc_val: 79.3458 **\n",
      "Validation: Epoch 6,  val_loss:0.6300, aupr_val: 72.22, auc_val: 80.57\n",
      "**[S] Epoch 6, aupr_val: 72.2168, auc_val: 80.5741 **\n",
      "Validation: Epoch 7,  val_loss:0.6330, aupr_val: 73.86, auc_val: 80.89\n",
      "**[S] Epoch 7, aupr_val: 73.8572, auc_val: 80.8945 **\n",
      "Validation: Epoch 8,  val_loss:0.6169, aupr_val: 73.47, auc_val: 81.21\n",
      "**[S] Epoch 8, aupr_val: 73.4665, auc_val: 81.2150 **\n",
      "Validation: Epoch 9,  val_loss:0.6034, aupr_val: 73.41, auc_val: 81.30\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-04.\n",
      "**[S] Epoch 9, aupr_val: 73.4150, auc_val: 81.2951 **\n",
      "Validation: Epoch 10,  val_loss:0.6055, aupr_val: 73.56, auc_val: 81.35\n",
      "**[S] Epoch 10, aupr_val: 73.5643, auc_val: 81.3485 **\n",
      "Validation: Epoch 11,  val_loss:0.6072, aupr_val: 73.42, auc_val: 81.35\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 12,  val_loss:0.6073, aupr_val: 73.40, auc_val: 81.32\n",
      "Validation: Epoch 13,  val_loss:0.6072, aupr_val: 73.40, auc_val: 81.32\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 14,  val_loss:0.6072, aupr_val: 73.40, auc_val: 81.32\n",
      "Validation: Epoch 15,  val_loss:0.6072, aupr_val: 73.40, auc_val: 81.32\n",
      "Epoch 00016: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 16,  val_loss:0.6072, aupr_val: 73.40, auc_val: 81.32\n",
      "Validation: Epoch 17,  val_loss:0.6072, aupr_val: 73.40, auc_val: 81.32\n",
      "Epoch 00018: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 18,  val_loss:0.6072, aupr_val: 73.40, auc_val: 81.32\n",
      "Validation: Epoch 19,  val_loss:0.6072, aupr_val: 73.40, auc_val: 81.32\n",
      "Total Time elapsed: 0.123 mins\n",
      "    course  percentile       acc       bac       auc     auprc\n",
      "0  dsp-006          60  0.809524  0.733108  0.713088  0.550311\n",
      "Split id: 1\n",
      "394 49 50 394 49 50\n",
      "[289] [36] [36]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([394, 1000, 24]) torch.Size([394, 9]) torch.Size([394, 1000, 1]) torch.Size([394])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.7158, aupr_val: 58.16, auc_val: 18.70\n",
      "**[S] Epoch 0, aupr_val: 58.1610, auc_val: 18.6966 **\n",
      "Validation: Epoch 1,  val_loss:0.7068, aupr_val: 64.76, auc_val: 21.37\n",
      "**[S] Epoch 1, aupr_val: 64.7628, auc_val: 21.3675 **\n",
      "Validation: Epoch 2,  val_loss:0.6994, aupr_val: 91.59, auc_val: 81.30\n",
      "**[S] Epoch 2, aupr_val: 91.5893, auc_val: 81.3034 **\n",
      "Validation: Epoch 3,  val_loss:0.6929, aupr_val: 91.59, auc_val: 81.30\n",
      "Validation: Epoch 4,  val_loss:0.6880, aupr_val: 91.59, auc_val: 81.30\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 5,  val_loss:0.6877, aupr_val: 91.59, auc_val: 81.30\n",
      "Validation: Epoch 6,  val_loss:0.6874, aupr_val: 91.59, auc_val: 81.30\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 7,  val_loss:0.6874, aupr_val: 91.59, auc_val: 81.30\n",
      "Validation: Epoch 8,  val_loss:0.6874, aupr_val: 91.59, auc_val: 81.30\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 9,  val_loss:0.6874, aupr_val: 91.59, auc_val: 81.30\n",
      "Validation: Epoch 10,  val_loss:0.6874, aupr_val: 91.59, auc_val: 81.30\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 11,  val_loss:0.6874, aupr_val: 91.59, auc_val: 81.30\n",
      "Validation: Epoch 12,  val_loss:0.6874, aupr_val: 91.59, auc_val: 81.30\n",
      "Epoch 00013: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 13,  val_loss:0.6874, aupr_val: 91.59, auc_val: 81.30\n",
      "Validation: Epoch 14,  val_loss:0.6874, aupr_val: 91.59, auc_val: 81.30\n",
      "Validation: Epoch 15,  val_loss:0.6874, aupr_val: 91.59, auc_val: 81.30\n",
      "Validation: Epoch 16,  val_loss:0.6874, aupr_val: 91.59, auc_val: 81.30\n",
      "Validation: Epoch 17,  val_loss:0.6874, aupr_val: 91.59, auc_val: 81.30\n",
      "Validation: Epoch 18,  val_loss:0.6874, aupr_val: 91.59, auc_val: 81.30\n",
      "Validation: Epoch 19,  val_loss:0.6874, aupr_val: 91.59, auc_val: 81.30\n",
      "Total Time elapsed: 0.011 mins\n",
      "                 course  percentile       acc  bac      auc     auprc\n",
      "0  analysenumerique-002          40  0.294118  0.5  0.27963  0.577404\n",
      "Split id: 1\n",
      "396 49 50 396 49 50\n",
      "[289] [36] [36]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([396, 1000, 24]) torch.Size([396, 9]) torch.Size([396, 1000, 1]) torch.Size([396])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6723, aupr_val: 56.85, auc_val: 14.74\n",
      "**[S] Epoch 0, aupr_val: 56.8546, auc_val: 14.7436 **\n",
      "Validation: Epoch 1,  val_loss:0.6783, aupr_val: 56.85, auc_val: 14.74\n",
      "Validation: Epoch 2,  val_loss:0.6844, aupr_val: 56.85, auc_val: 14.74\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.6849, aupr_val: 56.85, auc_val: 14.74\n",
      "Validation: Epoch 4,  val_loss:0.6855, aupr_val: 56.85, auc_val: 14.74\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.6856, aupr_val: 56.85, auc_val: 14.74\n",
      "Validation: Epoch 6,  val_loss:0.6856, aupr_val: 56.85, auc_val: 14.74\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.6856, aupr_val: 56.85, auc_val: 14.74\n",
      "Validation: Epoch 8,  val_loss:0.6856, aupr_val: 56.85, auc_val: 14.74\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.6856, aupr_val: 56.85, auc_val: 14.74\n",
      "Validation: Epoch 10,  val_loss:0.6856, aupr_val: 56.85, auc_val: 14.74\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.6856, aupr_val: 56.85, auc_val: 14.74\n",
      "Validation: Epoch 12,  val_loss:0.6856, aupr_val: 56.85, auc_val: 14.74\n",
      "Validation: Epoch 13,  val_loss:0.6856, aupr_val: 56.85, auc_val: 14.74\n",
      "Validation: Epoch 14,  val_loss:0.6856, aupr_val: 56.85, auc_val: 14.74\n",
      "Validation: Epoch 15,  val_loss:0.6856, aupr_val: 56.85, auc_val: 14.74\n",
      "Validation: Epoch 16,  val_loss:0.6856, aupr_val: 56.85, auc_val: 14.74\n",
      "Validation: Epoch 17,  val_loss:0.6856, aupr_val: 56.85, auc_val: 14.74\n",
      "Validation: Epoch 18,  val_loss:0.6856, aupr_val: 56.85, auc_val: 14.74\n",
      "Validation: Epoch 19,  val_loss:0.6856, aupr_val: 56.85, auc_val: 14.74\n",
      "Total Time elapsed: 0.011 mins\n",
      "                 course  percentile      acc       bac       auc    auprc\n",
      "0  analysenumerique-002          60  0.72549  0.533333  0.892593  0.90964\n",
      "Split id: 1\n",
      "138 17 18 138 17 18\n",
      "[43] [5] [6]\n",
      "torch.Size([138, 1000, 26]) torch.Size([138, 9]) torch.Size([138, 1000, 1]) torch.Size([138])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6875, aupr_val: 30.08, auc_val: 47.50\n",
      "**[S] Epoch 0, aupr_val: 30.0823, auc_val: 47.5000 **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch 1,  val_loss:0.6932, aupr_val: 30.08, auc_val: 47.50\n",
      "Validation: Epoch 2,  val_loss:0.6984, aupr_val: 28.81, auc_val: 44.17\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.6989, aupr_val: 28.81, auc_val: 44.17\n",
      "Validation: Epoch 4,  val_loss:0.6992, aupr_val: 30.52, auc_val: 47.50\n",
      "Validation: Epoch 5,  val_loss:0.6995, aupr_val: 32.35, auc_val: 52.50\n",
      "**[S] Epoch 5, aupr_val: 32.3460, auc_val: 52.5000 **\n",
      "Validation: Epoch 6,  val_loss:0.6997, aupr_val: 32.35, auc_val: 52.50\n",
      "Validation: Epoch 7,  val_loss:0.6998, aupr_val: 32.35, auc_val: 52.50\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 8,  val_loss:0.6998, aupr_val: 32.35, auc_val: 52.50\n",
      "Validation: Epoch 9,  val_loss:0.6998, aupr_val: 32.35, auc_val: 52.50\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 10,  val_loss:0.6998, aupr_val: 32.35, auc_val: 52.50\n",
      "Validation: Epoch 11,  val_loss:0.6998, aupr_val: 32.35, auc_val: 52.50\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 12,  val_loss:0.6998, aupr_val: 32.35, auc_val: 52.50\n",
      "Validation: Epoch 13,  val_loss:0.6998, aupr_val: 32.35, auc_val: 52.50\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 14,  val_loss:0.6998, aupr_val: 32.35, auc_val: 52.50\n",
      "Validation: Epoch 15,  val_loss:0.6998, aupr_val: 32.35, auc_val: 52.50\n",
      "Validation: Epoch 16,  val_loss:0.6998, aupr_val: 32.35, auc_val: 52.50\n",
      "Validation: Epoch 17,  val_loss:0.6998, aupr_val: 32.35, auc_val: 52.50\n",
      "Validation: Epoch 18,  val_loss:0.6998, aupr_val: 32.35, auc_val: 52.50\n",
      "Validation: Epoch 19,  val_loss:0.6998, aupr_val: 32.35, auc_val: 52.50\n",
      "Total Time elapsed: 0.012 mins\n",
      "           course  percentile       acc  bac       auc     auprc\n",
      "0  structures-003          40  0.333333  0.5  0.305556  0.321639\n",
      "Split id: 1\n",
      "138 17 18 138 17 18\n",
      "[43] [5] [6]\n",
      "torch.Size([138, 1000, 26]) torch.Size([138, 9]) torch.Size([138, 1000, 1]) torch.Size([138])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6977, aupr_val: 44.13, auc_val: 68.33\n",
      "**[S] Epoch 0, aupr_val: 44.1270, auc_val: 68.3333 **\n",
      "Validation: Epoch 1,  val_loss:0.6957, aupr_val: 44.13, auc_val: 68.33\n",
      "Validation: Epoch 2,  val_loss:0.6936, aupr_val: 44.13, auc_val: 68.33\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch 3,  val_loss:0.6934, aupr_val: 44.13, auc_val: 68.33\n",
      "Validation: Epoch 4,  val_loss:0.6933, aupr_val: 40.31, auc_val: 61.67\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.6933, aupr_val: 36.97, auc_val: 60.00\n",
      "Validation: Epoch 6,  val_loss:0.6933, aupr_val: 36.97, auc_val: 60.00\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.6933, aupr_val: 36.97, auc_val: 60.00\n",
      "Validation: Epoch 8,  val_loss:0.6933, aupr_val: 36.97, auc_val: 60.00\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.6933, aupr_val: 36.97, auc_val: 60.00\n",
      "Validation: Epoch 10,  val_loss:0.6933, aupr_val: 36.97, auc_val: 60.00\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.6933, aupr_val: 36.97, auc_val: 60.00\n",
      "Validation: Epoch 12,  val_loss:0.6933, aupr_val: 36.97, auc_val: 60.00\n",
      "Validation: Epoch 13,  val_loss:0.6933, aupr_val: 36.97, auc_val: 60.00\n",
      "Validation: Epoch 14,  val_loss:0.6933, aupr_val: 36.97, auc_val: 60.00\n",
      "Validation: Epoch 15,  val_loss:0.6933, aupr_val: 36.97, auc_val: 60.00\n",
      "Validation: Epoch 16,  val_loss:0.6933, aupr_val: 36.97, auc_val: 60.00\n",
      "Validation: Epoch 17,  val_loss:0.6933, aupr_val: 36.97, auc_val: 60.00\n",
      "Validation: Epoch 18,  val_loss:0.6933, aupr_val: 36.97, auc_val: 60.00\n",
      "Validation: Epoch 19,  val_loss:0.6933, aupr_val: 36.97, auc_val: 60.00\n",
      "Total Time elapsed: 0.011 mins\n",
      "           course  percentile       acc       bac       auc     auprc\n",
      "0  structures-003          60  0.222222  0.333333  0.208333  0.295592\n",
      "Split id: 1\n",
      "1548 197 202 1548 197 202\n",
      "[163] [21] [21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1548, 1000, 26]) torch.Size([1548, 9]) torch.Size([1548, 1000, 1]) torch.Size([1548])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.7008, aupr_val: 20.62, auc_val: 38.72\n",
      "**[S] Epoch 0, aupr_val: 20.6176, auc_val: 38.7175 **\n",
      "Validation: Epoch 1,  val_loss:0.6786, aupr_val: 24.07, auc_val: 39.61\n",
      "**[S] Epoch 1, aupr_val: 24.0747, auc_val: 39.6104 **\n",
      "Validation: Epoch 2,  val_loss:0.6842, aupr_val: 24.22, auc_val: 39.83\n",
      "**[S] Epoch 2, aupr_val: 24.2159, auc_val: 39.8268 **\n",
      "Validation: Epoch 3,  val_loss:0.6902, aupr_val: 24.65, auc_val: 40.21\n",
      "**[S] Epoch 3, aupr_val: 24.6545, auc_val: 40.2056 **\n",
      "Validation: Epoch 4,  val_loss:0.6907, aupr_val: 24.65, auc_val: 40.18\n",
      "Validation: Epoch 5,  val_loss:0.6863, aupr_val: 24.65, auc_val: 40.18\n",
      "Epoch 00006: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 6,  val_loss:0.6861, aupr_val: 24.65, auc_val: 40.18\n",
      "Validation: Epoch 7,  val_loss:0.6863, aupr_val: 24.65, auc_val: 40.18\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 8,  val_loss:0.6863, aupr_val: 24.65, auc_val: 40.18\n",
      "Validation: Epoch 9,  val_loss:0.6863, aupr_val: 24.65, auc_val: 40.18\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 10,  val_loss:0.6863, aupr_val: 24.65, auc_val: 40.18\n",
      "Validation: Epoch 11,  val_loss:0.6863, aupr_val: 24.65, auc_val: 40.18\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 12,  val_loss:0.6863, aupr_val: 24.65, auc_val: 40.18\n",
      "Validation: Epoch 13,  val_loss:0.6863, aupr_val: 24.65, auc_val: 40.18\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 14,  val_loss:0.6863, aupr_val: 24.65, auc_val: 40.18\n",
      "Validation: Epoch 15,  val_loss:0.6863, aupr_val: 24.65, auc_val: 40.18\n",
      "Validation: Epoch 16,  val_loss:0.6863, aupr_val: 24.65, auc_val: 40.18\n",
      "Validation: Epoch 17,  val_loss:0.6863, aupr_val: 24.65, auc_val: 40.18\n",
      "Validation: Epoch 18,  val_loss:0.6863, aupr_val: 24.65, auc_val: 40.18\n",
      "Validation: Epoch 19,  val_loss:0.6863, aupr_val: 24.65, auc_val: 40.18\n",
      "Total Time elapsed: 0.071 mins\n",
      "                 course  percentile       acc     bac       auc     auprc\n",
      "0  microcontroleurs-005          40  0.939394  0.6408  0.579365  0.337518\n",
      "Split id: 1\n",
      "1762 221 226 1762 221 226\n",
      "[169] [21] [21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1762, 1000, 26]) torch.Size([1762, 9]) torch.Size([1762, 1000, 1]) torch.Size([1762])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6718, aupr_val: 24.32, auc_val: 59.27\n",
      "**[S] Epoch 0, aupr_val: 24.3193, auc_val: 59.2738 **\n",
      "Validation: Epoch 1,  val_loss:0.6654, aupr_val: 46.26, auc_val: 84.54\n",
      "**[S] Epoch 1, aupr_val: 46.2584, auc_val: 84.5357 **\n",
      "Validation: Epoch 2,  val_loss:0.6800, aupr_val: 47.35, auc_val: 84.61\n",
      "**[S] Epoch 2, aupr_val: 47.3464, auc_val: 84.6071 **\n",
      "Validation: Epoch 3,  val_loss:0.6692, aupr_val: 48.96, auc_val: 84.63\n",
      "**[S] Epoch 3, aupr_val: 48.9625, auc_val: 84.6310 **\n",
      "Validation: Epoch 4,  val_loss:0.6541, aupr_val: 34.09, auc_val: 46.62\n",
      "Validation: Epoch 5,  val_loss:0.6452, aupr_val: 34.49, auc_val: 46.63\n",
      "Epoch 00006: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 6,  val_loss:0.6429, aupr_val: 34.49, auc_val: 46.65\n",
      "Validation: Epoch 7,  val_loss:0.6406, aupr_val: 34.49, auc_val: 46.63\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 8,  val_loss:0.6404, aupr_val: 34.49, auc_val: 46.65\n",
      "Validation: Epoch 9,  val_loss:0.6403, aupr_val: 34.49, auc_val: 46.65\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 10,  val_loss:0.6403, aupr_val: 34.49, auc_val: 46.65\n",
      "Validation: Epoch 11,  val_loss:0.6403, aupr_val: 34.49, auc_val: 46.65\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 12,  val_loss:0.6403, aupr_val: 34.49, auc_val: 46.65\n",
      "Validation: Epoch 13,  val_loss:0.6403, aupr_val: 34.49, auc_val: 46.65\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 14,  val_loss:0.6403, aupr_val: 34.49, auc_val: 46.65\n",
      "Validation: Epoch 15,  val_loss:0.6403, aupr_val: 34.49, auc_val: 46.64\n",
      "Validation: Epoch 16,  val_loss:0.6403, aupr_val: 34.49, auc_val: 46.64\n",
      "Validation: Epoch 17,  val_loss:0.6403, aupr_val: 34.49, auc_val: 46.64\n",
      "Validation: Epoch 18,  val_loss:0.6403, aupr_val: 34.49, auc_val: 46.64\n",
      "Validation: Epoch 19,  val_loss:0.6403, aupr_val: 34.49, auc_val: 46.64\n",
      "Total Time elapsed: 0.071 mins\n",
      "                 course  percentile       acc       bac       auc    auprc\n",
      "0  microcontroleurs-005          60  0.924242  0.654321  0.495395  0.29462\n",
      "Split id: 1\n",
      "1910 256 231 1910 256 231\n",
      "[75] [9] [10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1910, 1000, 24]) torch.Size([1910, 9]) torch.Size([1910, 1000, 1]) torch.Size([1910])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.7218, aupr_val: 2.10, auc_val: 10.53\n",
      "**[S] Epoch 0, aupr_val: 2.1040, auc_val: 10.5263 **\n",
      "Validation: Epoch 1,  val_loss:0.7124, aupr_val: 2.10, auc_val: 10.12\n",
      "Validation: Epoch 2,  val_loss:0.7089, aupr_val: 2.10, auc_val: 10.12\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.7093, aupr_val: 2.10, auc_val: 10.12\n",
      "Validation: Epoch 4,  val_loss:0.7099, aupr_val: 2.10, auc_val: 10.12\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.7100, aupr_val: 2.10, auc_val: 10.12\n",
      "Validation: Epoch 6,  val_loss:0.7101, aupr_val: 2.10, auc_val: 10.12\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.7101, aupr_val: 2.10, auc_val: 10.12\n",
      "Validation: Epoch 8,  val_loss:0.7101, aupr_val: 2.10, auc_val: 10.12\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.7101, aupr_val: 2.10, auc_val: 10.12\n",
      "Validation: Epoch 10,  val_loss:0.7101, aupr_val: 2.10, auc_val: 10.12\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.7101, aupr_val: 2.10, auc_val: 10.12\n",
      "Validation: Epoch 12,  val_loss:0.7101, aupr_val: 2.10, auc_val: 10.12\n",
      "Validation: Epoch 13,  val_loss:0.7101, aupr_val: 2.10, auc_val: 10.12\n",
      "Validation: Epoch 14,  val_loss:0.7101, aupr_val: 2.10, auc_val: 10.12\n",
      "Validation: Epoch 15,  val_loss:0.7101, aupr_val: 2.10, auc_val: 10.12\n",
      "Validation: Epoch 16,  val_loss:0.7101, aupr_val: 2.10, auc_val: 10.12\n",
      "Validation: Epoch 17,  val_loss:0.7101, aupr_val: 2.10, auc_val: 10.12\n",
      "Validation: Epoch 18,  val_loss:0.7101, aupr_val: 2.10, auc_val: 10.12\n",
      "Validation: Epoch 19,  val_loss:0.7101, aupr_val: 2.10, auc_val: 10.12\n",
      "Total Time elapsed: 0.033 mins\n",
      "        course  percentile       acc       bac       auc     auprc\n",
      "0  venture-001          40  0.311526  0.644695  0.865113  0.236812\n",
      "Split id: 1\n",
      "2197 282 277 2197 282 277\n",
      "[77] [9] [10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2197, 1000, 24]) torch.Size([2197, 9]) torch.Size([2197, 1000, 1]) torch.Size([2197])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.7227, aupr_val: 29.07, auc_val: 84.25\n",
      "**[S] Epoch 0, aupr_val: 29.0706, auc_val: 84.2491 **\n",
      "Validation: Epoch 1,  val_loss:0.6997, aupr_val: 12.95, auc_val: 17.42\n",
      "Validation: Epoch 2,  val_loss:0.6806, aupr_val: 12.95, auc_val: 17.42\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.6800, aupr_val: 7.39, auc_val: 17.38\n",
      "Validation: Epoch 4,  val_loss:0.6803, aupr_val: 7.39, auc_val: 17.38\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.6804, aupr_val: 7.39, auc_val: 17.38\n",
      "Validation: Epoch 6,  val_loss:0.6805, aupr_val: 7.39, auc_val: 17.38\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.6805, aupr_val: 7.39, auc_val: 17.38\n",
      "Validation: Epoch 8,  val_loss:0.6806, aupr_val: 7.39, auc_val: 17.38\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.6806, aupr_val: 7.39, auc_val: 17.38\n",
      "Validation: Epoch 10,  val_loss:0.6806, aupr_val: 7.39, auc_val: 17.38\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.6806, aupr_val: 7.39, auc_val: 17.38\n",
      "Validation: Epoch 12,  val_loss:0.6806, aupr_val: 7.39, auc_val: 17.38\n",
      "Validation: Epoch 13,  val_loss:0.6806, aupr_val: 7.39, auc_val: 17.38\n",
      "Validation: Epoch 14,  val_loss:0.6806, aupr_val: 7.39, auc_val: 17.38\n",
      "Validation: Epoch 15,  val_loss:0.6806, aupr_val: 7.39, auc_val: 17.38\n",
      "Validation: Epoch 16,  val_loss:0.6806, aupr_val: 7.39, auc_val: 17.38\n",
      "Validation: Epoch 17,  val_loss:0.6806, aupr_val: 7.39, auc_val: 17.38\n",
      "Validation: Epoch 18,  val_loss:0.6806, aupr_val: 7.39, auc_val: 17.38\n",
      "Validation: Epoch 19,  val_loss:0.6806, aupr_val: 7.39, auc_val: 17.38\n",
      "Total Time elapsed: 0.037 mins\n",
      "        course  percentile       acc      bac       auc     auprc\n",
      "0  venture-001          60  0.168224  0.57074  0.811254  0.158476\n",
      "Split id: 1\n",
      "395 50 51 395 50 51\n",
      "[34] [4] [5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([395, 1000, 12]) torch.Size([395, 9]) torch.Size([395, 1000, 1]) torch.Size([395])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.7117, aupr_val: 21.50, auc_val: 61.68\n",
      "**[S] Epoch 0, aupr_val: 21.5035, auc_val: 61.6848 **\n",
      "Validation: Epoch 1,  val_loss:0.7052, aupr_val: 21.50, auc_val: 61.68\n",
      "Validation: Epoch 2,  val_loss:0.7003, aupr_val: 21.50, auc_val: 61.68\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.6998, aupr_val: 21.50, auc_val: 61.68\n",
      "Validation: Epoch 4,  val_loss:0.6994, aupr_val: 21.50, auc_val: 61.68\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.6994, aupr_val: 21.50, auc_val: 61.68\n",
      "Validation: Epoch 6,  val_loss:0.6993, aupr_val: 21.50, auc_val: 61.68\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.6993, aupr_val: 21.50, auc_val: 61.68\n",
      "Validation: Epoch 8,  val_loss:0.6993, aupr_val: 21.50, auc_val: 61.68\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.6993, aupr_val: 21.50, auc_val: 61.68\n",
      "Validation: Epoch 10,  val_loss:0.6993, aupr_val: 21.50, auc_val: 61.68\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.6993, aupr_val: 21.50, auc_val: 61.68\n",
      "Validation: Epoch 12,  val_loss:0.6993, aupr_val: 21.50, auc_val: 61.68\n",
      "Validation: Epoch 13,  val_loss:0.6993, aupr_val: 21.50, auc_val: 61.68\n",
      "Validation: Epoch 14,  val_loss:0.6993, aupr_val: 21.50, auc_val: 61.68\n",
      "Validation: Epoch 15,  val_loss:0.6993, aupr_val: 21.50, auc_val: 61.68\n",
      "Validation: Epoch 16,  val_loss:0.6993, aupr_val: 21.50, auc_val: 61.68\n",
      "Validation: Epoch 17,  val_loss:0.6993, aupr_val: 21.50, auc_val: 61.68\n",
      "Validation: Epoch 18,  val_loss:0.6993, aupr_val: 21.50, auc_val: 61.68\n",
      "Validation: Epoch 19,  val_loss:0.6993, aupr_val: 21.50, auc_val: 61.68\n",
      "Total Time elapsed: 0.012 mins\n",
      "                 course  percentile       acc  bac       auc     auprc\n",
      "0  analysenumerique-001          40  0.098039  0.5  0.395652  0.094001\n",
      "Split id: 1\n",
      "398 50 51 398 50 51\n",
      "[34] [4] [5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([398, 1000, 12]) torch.Size([398, 9]) torch.Size([398, 1000, 1]) torch.Size([398])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6932, aupr_val: 36.38, auc_val: 63.86\n",
      "**[S] Epoch 0, aupr_val: 36.3799, auc_val: 63.8587 **\n",
      "Validation: Epoch 1,  val_loss:0.6969, aupr_val: 36.38, auc_val: 63.86\n",
      "Validation: Epoch 2,  val_loss:0.7002, aupr_val: 36.38, auc_val: 63.86\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.7005, aupr_val: 36.38, auc_val: 63.86\n",
      "Validation: Epoch 4,  val_loss:0.7006, aupr_val: 36.38, auc_val: 63.86\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.7006, aupr_val: 36.38, auc_val: 63.86\n",
      "Validation: Epoch 6,  val_loss:0.7006, aupr_val: 36.38, auc_val: 63.86\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.7006, aupr_val: 36.38, auc_val: 63.86\n",
      "Validation: Epoch 8,  val_loss:0.7006, aupr_val: 36.38, auc_val: 63.86\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.7006, aupr_val: 36.38, auc_val: 63.86\n",
      "Validation: Epoch 10,  val_loss:0.7006, aupr_val: 36.38, auc_val: 63.86\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.7006, aupr_val: 36.38, auc_val: 63.86\n",
      "Validation: Epoch 12,  val_loss:0.7006, aupr_val: 36.38, auc_val: 63.86\n",
      "Validation: Epoch 13,  val_loss:0.7006, aupr_val: 36.38, auc_val: 63.86\n",
      "Validation: Epoch 14,  val_loss:0.7006, aupr_val: 36.38, auc_val: 63.86\n",
      "Validation: Epoch 15,  val_loss:0.7006, aupr_val: 36.38, auc_val: 63.86\n",
      "Validation: Epoch 16,  val_loss:0.7006, aupr_val: 36.38, auc_val: 63.86\n",
      "Validation: Epoch 17,  val_loss:0.7006, aupr_val: 36.38, auc_val: 63.86\n",
      "Validation: Epoch 18,  val_loss:0.7006, aupr_val: 36.38, auc_val: 63.86\n",
      "Validation: Epoch 19,  val_loss:0.7006, aupr_val: 36.38, auc_val: 63.86\n",
      "Total Time elapsed: 0.011 mins\n",
      "                 course  percentile       acc       bac       auc     auprc\n",
      "0  analysenumerique-001          60  0.215686  0.565217  0.719565  0.226232\n",
      "Split id: 1\n",
      "595 77 76 595 77 76\n",
      "[234] [29] [31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([595, 1000, 26]) torch.Size([595, 9]) torch.Size([595, 1000, 1]) torch.Size([595])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6899, aupr_val: 37.12, auc_val: 47.45\n",
      "**[S] Epoch 0, aupr_val: 37.1197, auc_val: 47.4497 **\n",
      "Validation: Epoch 1,  val_loss:0.6892, aupr_val: 37.10, auc_val: 47.38\n",
      "Validation: Epoch 2,  val_loss:0.6917, aupr_val: 37.10, auc_val: 47.38\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.6919, aupr_val: 37.10, auc_val: 47.38\n",
      "Validation: Epoch 4,  val_loss:0.6922, aupr_val: 37.10, auc_val: 47.38\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.6922, aupr_val: 37.10, auc_val: 47.38\n",
      "Validation: Epoch 6,  val_loss:0.6922, aupr_val: 37.10, auc_val: 47.38\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.6922, aupr_val: 37.10, auc_val: 47.38\n",
      "Validation: Epoch 8,  val_loss:0.6922, aupr_val: 37.10, auc_val: 47.38\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.6922, aupr_val: 37.10, auc_val: 47.38\n",
      "Validation: Epoch 10,  val_loss:0.6922, aupr_val: 37.10, auc_val: 47.38\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.6922, aupr_val: 37.10, auc_val: 47.38\n",
      "Validation: Epoch 12,  val_loss:0.6922, aupr_val: 37.10, auc_val: 47.38\n",
      "Validation: Epoch 13,  val_loss:0.6922, aupr_val: 37.10, auc_val: 47.38\n",
      "Validation: Epoch 14,  val_loss:0.6922, aupr_val: 37.10, auc_val: 47.38\n",
      "Validation: Epoch 15,  val_loss:0.6922, aupr_val: 37.10, auc_val: 47.38\n",
      "Validation: Epoch 16,  val_loss:0.6922, aupr_val: 37.10, auc_val: 47.38\n",
      "Validation: Epoch 17,  val_loss:0.6922, aupr_val: 37.10, auc_val: 47.38\n",
      "Validation: Epoch 18,  val_loss:0.6922, aupr_val: 37.10, auc_val: 47.38\n",
      "Validation: Epoch 19,  val_loss:0.6922, aupr_val: 37.10, auc_val: 47.38\n",
      "Total Time elapsed: 0.048 mins\n",
      "       course  percentile      acc       bac       auc     auprc\n",
      "0  cpp-fr-001          40  0.64557  0.559812  0.512769  0.468285\n",
      "Split id: 1\n",
      "626 78 78 626 78 78\n",
      "[241] [29] [31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([626, 1000, 26]) torch.Size([626, 9]) torch.Size([626, 1000, 1]) torch.Size([626])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6870, aupr_val: 44.78, auc_val: 48.94\n",
      "**[S] Epoch 0, aupr_val: 44.7788, auc_val: 48.9444 **\n",
      "Validation: Epoch 1,  val_loss:0.6839, aupr_val: 44.49, auc_val: 48.66\n",
      "Validation: Epoch 2,  val_loss:0.6879, aupr_val: 44.43, auc_val: 48.52\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.6883, aupr_val: 44.35, auc_val: 48.31\n",
      "Validation: Epoch 4,  val_loss:0.6883, aupr_val: 44.53, auc_val: 48.73\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.6883, aupr_val: 44.53, auc_val: 48.73\n",
      "Validation: Epoch 6,  val_loss:0.6883, aupr_val: 44.53, auc_val: 48.73\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.6883, aupr_val: 44.53, auc_val: 48.73\n",
      "Validation: Epoch 8,  val_loss:0.6883, aupr_val: 44.53, auc_val: 48.73\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.6883, aupr_val: 44.53, auc_val: 48.73\n",
      "Validation: Epoch 10,  val_loss:0.6883, aupr_val: 44.53, auc_val: 48.73\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.6883, aupr_val: 44.53, auc_val: 48.73\n",
      "Validation: Epoch 12,  val_loss:0.6883, aupr_val: 44.53, auc_val: 48.73\n",
      "Validation: Epoch 13,  val_loss:0.6883, aupr_val: 44.53, auc_val: 48.73\n",
      "Validation: Epoch 14,  val_loss:0.6883, aupr_val: 44.53, auc_val: 48.73\n",
      "Validation: Epoch 15,  val_loss:0.6883, aupr_val: 44.53, auc_val: 48.73\n",
      "Validation: Epoch 16,  val_loss:0.6883, aupr_val: 44.53, auc_val: 48.73\n",
      "Validation: Epoch 17,  val_loss:0.6883, aupr_val: 44.53, auc_val: 48.73\n",
      "Validation: Epoch 18,  val_loss:0.6883, aupr_val: 44.53, auc_val: 48.73\n",
      "Validation: Epoch 19,  val_loss:0.6883, aupr_val: 44.53, auc_val: 48.73\n",
      "Total Time elapsed: 0.058 mins\n",
      "       course  percentile      acc       bac       auc     auprc\n",
      "0  cpp-fr-001          60  0.64557  0.559812  0.493952  0.472308\n",
      "Split id: 1\n",
      "73 9 10 73 9 10\n",
      "[50] [6] [7]\n",
      "torch.Size([73, 1000, 24]) torch.Size([73, 9]) torch.Size([73, 1000, 1]) torch.Size([73])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "**[S] Epoch 0, aupr_val: 67.4603, auc_val: 50.0000 **\n",
      "Validation: Epoch 1,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "Validation: Epoch 2,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "Validation: Epoch 4,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "Validation: Epoch 6,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "Validation: Epoch 8,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "Validation: Epoch 10,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "Validation: Epoch 12,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "Validation: Epoch 13,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "Validation: Epoch 14,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "Validation: Epoch 15,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "Validation: Epoch 16,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "Validation: Epoch 17,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "Validation: Epoch 18,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "Validation: Epoch 19,  val_loss:0.6956, aupr_val: 67.46, auc_val: 50.00\n",
      "Total Time elapsed: 0.002 mins\n",
      "           course  percentile  acc  bac       auc     auprc\n",
      "0  structures-001          40  0.3  0.5  0.571429  0.816327\n",
      "Split id: 1\n",
      "75 9 10 75 9 10\n",
      "[50] [6] [7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/envs/py39/lib/python3.9/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([75, 1000, 24]) torch.Size([75, 9]) torch.Size([75, 1000, 1]) torch.Size([75])\n",
      "- - Run 1 - -\n",
      "Validation: Epoch 0,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "**[S] Epoch 0, aupr_val: 59.3056, auc_val: 27.7778 **\n",
      "Validation: Epoch 1,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "Validation: Epoch 2,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Validation: Epoch 3,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "Validation: Epoch 4,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Validation: Epoch 5,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "Validation: Epoch 6,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Validation: Epoch 7,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "Validation: Epoch 8,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Validation: Epoch 9,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "Validation: Epoch 10,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Validation: Epoch 11,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "Validation: Epoch 12,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "Validation: Epoch 13,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "Validation: Epoch 14,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "Validation: Epoch 15,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "Validation: Epoch 16,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "Validation: Epoch 17,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "Validation: Epoch 18,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "Validation: Epoch 19,  val_loss:0.7015, aupr_val: 59.31, auc_val: 27.78\n",
      "Total Time elapsed: 0.002 mins\n",
      "           course  percentile  acc       bac       auc     auprc\n",
      "0  structures-001          60  0.3  0.404762  0.333333  0.632993\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "\n",
    "imputation = 'no_imputation'\n",
    "\n",
    "arch = 'standard'\n",
    "\n",
    "model_path = '../../models/transformer/'\n",
    "\n",
    "dataset = 'P12'\n",
    "\n",
    "\n",
    "base_path = '/../data/prep_data'\n",
    "data_path = '/../data'\n",
    "\n",
    "\n",
    "\n",
    "def one_hot(y_):\n",
    "    y_ = y_.reshape(len(y_))\n",
    "    y_ = [int(x) for x in y_]\n",
    "    n_values = np.max(y_) + 1\n",
    "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]\n",
    "\n",
    "feature_removal_level = 'no_removal'\n",
    "\n",
    "\n",
    "for MOOC_idx, MOOC in enumerate(MOOCs_list):\n",
    "    \n",
    "    for percentile in [40, 60]:\n",
    "        \n",
    "        \n",
    "        d_inp = dims[percentile][MOOC_idx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        missing_ratio = 0\n",
    "\n",
    "\n",
    "        num_epochs = 20\n",
    "        learning_rate = 0.001\n",
    "\n",
    "\n",
    "        d_static = 9\n",
    "\n",
    "        static_info = 0\n",
    "\n",
    "\n",
    "        d_model = d_inp\n",
    "        nhid = 2 * d_model\n",
    "        nlayers = 1\n",
    "        nhead = 1\n",
    "\n",
    "        dropout = 0.3\n",
    "\n",
    "\n",
    "        max_len = 1000\n",
    "        n_classes = 2\n",
    "\n",
    "\n",
    "        aggreg = 'mean'\n",
    "\n",
    "        MAX = 100\n",
    "\n",
    "        n_runs = 1\n",
    "        n_splits = 1\n",
    "        subset = False\n",
    "\n",
    "        split = 'random'\n",
    "        reverse = False\n",
    "        baseline = True\n",
    "\n",
    "        acc_arr = np.zeros((n_splits, n_runs))\n",
    "        auprc_arr = np.zeros((n_splits, n_runs))\n",
    "        auroc_arr = np.zeros((n_splits, n_runs))\n",
    "        precision_arr = np.zeros((n_splits, n_runs))\n",
    "        recall_arr = np.zeros((n_splits, n_runs))\n",
    "        F1_arr = np.zeros((n_splits, n_runs))\n",
    "\n",
    "        for k in range(n_splits):\n",
    "            split_idx = k + 1\n",
    "            print('Split id: %d' % split_idx)\n",
    "\n",
    "            #if dataset == 'P12':\n",
    "            #    if subset == True:\n",
    "            #        split_path = '/splits/phy12_split_subset' + str(split_idx) + '.npy'\n",
    "            #    else:\n",
    "            #        split_path = '/splits/phy12_split' + str(split_idx) + '.npy'\n",
    "            #elif dataset == 'P19':\n",
    "            #    split_path = '/splits/phy19_split' + str(split_idx) + '_new.npy'\n",
    "            #elif dataset == 'eICU':\n",
    "            #    split_path = '/splits/eICU_split' + str(split_idx) + '.npy'\n",
    "            #elif dataset == 'PAM':\n",
    "            #    split_path = '/splits/PAM_split_' + str(split_idx) + '.npy'\n",
    "\n",
    "\n",
    "            # prepare the data:\n",
    "            #Ptrain, Pval, Ptest, ytrain, yval, ytest = get_data_split(base_path, split_path, split_type=split,\n",
    "            #                                                          reverse=reverse, baseline=baseline, dataset=dataset,\n",
    "            #                                                          predictive_label=args.predictive_label)\n",
    "            Pdict_list = np.load(os.path.join(base_path, f\"{MOOC}_{percentile}_data_hard_fail.npy\"), allow_pickle=True)\n",
    "            arr_outcomes = np.load(os.path.join(base_path, f\"{MOOC}_{percentile}_y_hard_fail.npy\"), allow_pickle=True)\n",
    "\n",
    "            #Ptrain, Ptest, ytrain, ytest = train_test_split(Pdict_list, arr_outcomes, test_size=0.1, random_state=1)\n",
    "            #Ptrain, Pval, ytrain, yval = train_test_split(Ptrain, ytrain, test_size=1/9, random_state=1)\n",
    "            args_train, args_val, args_test = np.load(os.path.join(data_path, \n",
    "                                                                           'split_args', f\"split_{MOOC.replace('-', '_')}.npy\"),\n",
    "                                                             allow_pickle=True)\n",
    "            Ptrain = Pdict_list[args_train]\n",
    "            Pval = Pdict_list[args_val]\n",
    "            Ptest = Pdict_list[args_test]\n",
    "            ytrain = arr_outcomes[args_train, :]\n",
    "            yval = arr_outcomes[args_val, :]\n",
    "            ytest = arr_outcomes[args_test, :]\n",
    "\n",
    "\n",
    "            zero_indices = [i for i, item in enumerate(Ptrain) if item['length'] == 0]\n",
    "            #zero_Ptrain = Ptrain[zero_indices]\n",
    "            Ptrain = np.delete(Ptrain, zero_indices, axis=0)\n",
    "            ytrain = np.delete(ytrain, zero_indices, axis=0)\n",
    "\n",
    "            zero_indices = [i for i, item in enumerate(Pval) if item['length'] == 0]\n",
    "            zero_yval = yval[zero_indices]\n",
    "            Pval = np.delete(Pval, zero_indices, axis=0)\n",
    "            yval = np.delete(yval, zero_indices, axis=0)\n",
    "\n",
    "            zero_indices = [i for i, item in enumerate(Ptest) if item['length'] == 0]\n",
    "            zero_ytest = ytest[zero_indices]\n",
    "            Ptest = np.delete(Ptest, zero_indices, axis=0)  \n",
    "            ytest = np.delete(ytest, zero_indices, axis=0)\n",
    "\n",
    "            print(len(Ptrain), len(Pval), len(Ptest), len(ytrain), len(yval), len(ytest))\n",
    "            print(sum(ytrain), sum(yval), sum(ytest))\n",
    "\n",
    "            # impute missing values\n",
    "            if imputation != 'no_imputation':\n",
    "                if dataset == 'P12' or dataset == 'P19' or dataset == 'eICU':\n",
    "                    X_features_train = np.array([d['arr'] for d in Ptrain])\n",
    "                    X_time_train = np.array([d['time'] for d in Ptrain])\n",
    "                    X_features_val = np.array([d['arr'] for d in Pval])\n",
    "                    X_time_val = np.array([d['time'] for d in Pval])\n",
    "                    X_features_test = np.array([d['arr'] for d in Ptest])\n",
    "                    X_time_test = np.array([d['time'] for d in Ptest])\n",
    "                elif dataset == 'PAM':\n",
    "                    X_features_train = Ptrain\n",
    "                    X_time_train = np.array([np.arange(1, Ptrain.shape[1] + 1)[..., np.newaxis] for d in Ptrain])\n",
    "                    X_features_val = Pval\n",
    "                    X_time_val = np.array([np.arange(1, Pval.shape[1] + 1)[..., np.newaxis] for d in Pval])\n",
    "                    X_features_test = Ptest\n",
    "                    X_time_test = np.array([np.arange(1, Ptest.shape[1] + 1)[..., np.newaxis] for d in Ptest])\n",
    "\n",
    "                if dataset == 'P12' or dataset == 'P19' or dataset == 'PAM':\n",
    "                    missing_value_num = 0\n",
    "                elif dataset == 'eICU':\n",
    "                    missing_value_num = -1\n",
    "\n",
    "                if imputation == 'mean':\n",
    "                    features_means = get_features_mean(X_features_train)\n",
    "                    X_features_train = mean_imputation(X_features_train, X_time_train, features_means, missing_value_num)\n",
    "                    X_features_val = mean_imputation(X_features_val, X_time_val, features_means, missing_value_num)\n",
    "                    X_features_test = mean_imputation(X_features_test, X_time_test, features_means, missing_value_num)\n",
    "                elif imputation == 'forward':\n",
    "                    X_features_train = forward_imputation(X_features_train, X_time_train, missing_value_num)\n",
    "                    X_features_val = forward_imputation(X_features_val, X_time_val, missing_value_num)\n",
    "                    X_features_test = forward_imputation(X_features_test, X_time_test, missing_value_num)\n",
    "                elif imputation == 'cubic_spline':\n",
    "                    X_features_train = cubic_spline_imputation(X_features_train, X_time_train, missing_value_num)\n",
    "                    X_features_val = cubic_spline_imputation(X_features_val, X_time_val, missing_value_num)\n",
    "                    X_features_test = cubic_spline_imputation(X_features_test, X_time_test, missing_value_num)\n",
    "\n",
    "                if dataset == 'P12' or dataset == 'P19' or dataset == 'eICU':\n",
    "                    for i, pat in enumerate(X_features_train):\n",
    "                        Ptrain[i]['arr'] = pat\n",
    "                    for i, pat in enumerate(X_features_val):\n",
    "                        Pval[i]['arr'] = pat\n",
    "                    for i, pat in enumerate(X_features_test):\n",
    "                        Ptest[i]['arr'] = pat\n",
    "                elif dataset == 'PAM':\n",
    "                    for i, pat in enumerate(X_features_train):\n",
    "                        Ptrain[i] = pat\n",
    "                    for i, pat in enumerate(X_features_val):\n",
    "                        Pval[i] = pat\n",
    "                    for i, pat in enumerate(X_features_test):\n",
    "                        Ptest[i] = pat\n",
    "\n",
    "            if dataset == 'P12' or dataset == 'P19' or dataset == 'eICU':\n",
    "                T, F = Ptrain[0]['arr'].shape\n",
    "                D = len(Ptrain[0]['extended_static'])\n",
    "\n",
    "                Ptrain_tensor = np.zeros((len(Ptrain), T, F))\n",
    "                Ptrain_static_tensor = np.zeros((len(Ptrain), D))\n",
    "\n",
    "                for i in range(len(Ptrain)):\n",
    "                    Ptrain_tensor[i] = Ptrain[i]['arr']\n",
    "                    Ptrain_static_tensor[i] = Ptrain[i]['extended_static']\n",
    "\n",
    "                mf, stdf = getStats(Ptrain_tensor)\n",
    "                ms, ss = getStats_static(Ptrain_static_tensor, dataset=dataset)\n",
    "\n",
    "                Ptrain_tensor, Ptrain_static_tensor, Ptrain_time_tensor, ytrain_tensor = tensorize_normalize(Ptrain, ytrain,\n",
    "                                                                                                             mf,\n",
    "                                                                                                             stdf, ms, ss)\n",
    "                Pval_tensor, Pval_static_tensor, Pval_time_tensor, yval_tensor = tensorize_normalize(Pval, yval, mf, stdf,\n",
    "                                                                                                     ms, ss)\n",
    "                Ptest_tensor, Ptest_static_tensor, Ptest_time_tensor, ytest_tensor = tensorize_normalize(Ptest, ytest, mf,\n",
    "                                                                                                         stdf, ms,\n",
    "                                                                                                         ss)\n",
    "\n",
    "                print(Ptrain_tensor.shape, Ptrain_static_tensor.shape, Ptrain_time_tensor.shape, ytrain_tensor.shape)\n",
    "            elif dataset == 'PAM':\n",
    "                T, F = Ptrain[0].shape\n",
    "                D = 1\n",
    "\n",
    "                Ptrain_tensor = Ptrain\n",
    "                Ptrain_static_tensor = np.zeros((len(Ptrain), D))\n",
    "\n",
    "                mf, stdf = getStats(Ptrain)\n",
    "                Ptrain_tensor, Ptrain_static_tensor, Ptrain_time_tensor, ytrain_tensor = tensorize_normalize_other(Ptrain, ytrain, mf, stdf)\n",
    "                Pval_tensor, Pval_static_tensor, Pval_time_tensor, yval_tensor = tensorize_normalize_other(Pval, yval, mf, stdf)\n",
    "                Ptest_tensor, Ptest_static_tensor, Ptest_time_tensor, ytest_tensor = tensorize_normalize_other(Ptest, ytest, mf, stdf)\n",
    "\n",
    "            # remove part of variables in validation and test set\n",
    "            if missing_ratio > 0:\n",
    "                num_all_features = Pval_tensor.shape[2]\n",
    "                num_missing_features = round(missing_ratio * num_all_features)\n",
    "                if feature_removal_level == 'sample':\n",
    "                    for i, patient in enumerate(Pval_tensor):\n",
    "                        idx = np.random.choice(num_all_features, num_missing_features, replace=False)\n",
    "                        patient[:, idx] = torch.zeros(Pval_tensor.shape[1], num_missing_features)  # values\n",
    "                        Pval_tensor[i] = patient\n",
    "                    for i, patient in enumerate(Ptest_tensor):\n",
    "                        idx = np.random.choice(num_all_features, num_missing_features, replace=False)\n",
    "                        patient[:, idx] = torch.zeros(Ptest_tensor.shape[1], num_missing_features)   # values\n",
    "                        Ptest_tensor[i] = patient\n",
    "                elif feature_removal_level == 'set':\n",
    "                    density_score_indices = np.load('saved/IG_density_scores_' + dataset + '.npy', allow_pickle=True)[:, 0]\n",
    "                    idx = density_score_indices[:num_missing_features].astype(int)\n",
    "                    Pval_tensor[:, :, idx] = torch.zeros(Pval_tensor.shape[0], Pval_tensor.shape[1], num_missing_features)\n",
    "                    Ptest_tensor[:, :, idx] = torch.zeros(Ptest_tensor.shape[0], Ptest_tensor.shape[1], num_missing_features)\n",
    "\n",
    "            Ptrain_tensor = Ptrain_tensor.permute(1, 0, 2)\n",
    "            Pval_tensor = Pval_tensor.permute(1, 0, 2)\n",
    "            Ptest_tensor = Ptest_tensor.permute(1, 0, 2)\n",
    "\n",
    "            Ptrain_time_tensor = Ptrain_time_tensor.squeeze(2).permute(1, 0)\n",
    "            Pval_time_tensor = Pval_time_tensor.squeeze(2).permute(1, 0)\n",
    "            Ptest_time_tensor = Ptest_time_tensor.squeeze(2).permute(1, 0)\n",
    "\n",
    "            for m in range(n_runs):\n",
    "                print('- - Run %d - -' % (m + 1))\n",
    "\n",
    "                if dataset == 'P12' or dataset == 'P19' or dataset == 'eICU':\n",
    "                    model = TransformerModel2(d_inp, d_model, nhead, nhid, nlayers, dropout, max_len,\n",
    "                                              d_static, MAX, 0.5, aggreg, n_classes, static=False)\n",
    "                elif dataset == 'PAM':\n",
    "                    model = TransformerModel2(d_inp, d_model, nhead, nhid, nlayers, dropout, max_len,\n",
    "                                              d_static, MAX, 0.5, aggreg, n_classes, static=False)\n",
    "\n",
    "                model = model.cuda()\n",
    "\n",
    "                criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "                scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1,\n",
    "                                                                       patience=1, threshold=0.0001, threshold_mode='rel',\n",
    "                                                                       cooldown=0, min_lr=1e-8, eps=1e-08, verbose=True)\n",
    "\n",
    "                idx_0 = np.where(ytrain == 0)[0]\n",
    "                idx_1 = np.where(ytrain == 1)[0]\n",
    "\n",
    "                if dataset == 'P12' or dataset == 'P19' or dataset == 'eICU':\n",
    "                    strategy = 2\n",
    "                elif dataset == 'PAM':\n",
    "                    strategy = 3\n",
    "\n",
    "                n0, n1 = len(idx_0), len(idx_1)\n",
    "                expanded_idx_1 = np.concatenate([idx_1, idx_1, idx_1], axis=0)\n",
    "                expanded_n1 = len(expanded_idx_1)\n",
    "\n",
    "                batch_size = 128\n",
    "                if strategy == 1:\n",
    "                    n_batches = 10\n",
    "                elif strategy == 2:\n",
    "                    K0 = n0 // int(batch_size / 2)\n",
    "                    K1 = expanded_n1 // int(batch_size / 2)\n",
    "                    n_batches = np.min([K0, K1])\n",
    "                elif strategy == 3:\n",
    "                    n_batches = 30\n",
    "\n",
    "                best_aupr_val = best_auc_val = 0.0\n",
    "\n",
    "                start = time.time()\n",
    "                if wandb:\n",
    "                    wandb.watch(model)\n",
    "                for epoch in range(num_epochs):\n",
    "                    model.train()\n",
    "\n",
    "                    if strategy == 2:\n",
    "                        np.random.shuffle(expanded_idx_1)\n",
    "                        I1 = expanded_idx_1\n",
    "                        np.random.shuffle(idx_0)\n",
    "                        I0 = idx_0\n",
    "\n",
    "                    for n in range(n_batches):\n",
    "                        if strategy == 1:\n",
    "                            idx = random_sample(idx_0, idx_1, batch_size)\n",
    "                        elif strategy == 2:\n",
    "                            \"\"\"In each batch=128, 64 positive samples, 64 negative samples\"\"\"\n",
    "                            idx0_batch = I0[n * int(batch_size / 2):(n + 1) * int(batch_size / 2)]\n",
    "                            idx1_batch = I1[n * int(batch_size / 2):(n + 1) * int(batch_size / 2)]\n",
    "                            idx = np.concatenate([idx0_batch, idx1_batch], axis=0)\n",
    "                        elif strategy == 3:\n",
    "                            idx = np.random.choice(list(range(Ptrain_tensor.shape[1])), size=int(batch_size), replace=False)\n",
    "                            # idx = random_sample_8(ytrain, batch_size)   # to balance dataset\n",
    "\n",
    "                        if dataset == 'P12' or dataset == 'P19' or dataset == 'eICU':\n",
    "                            P, Ptime, Pstatic, y = Ptrain_tensor[:, idx, :].cuda(), Ptrain_time_tensor[:, idx].cuda(), \\\n",
    "                                                   Ptrain_static_tensor[idx].cuda(), ytrain_tensor[idx].cuda()\n",
    "                        elif dataset == 'PAM':\n",
    "                            P, Ptime, Pstatic, y = Ptrain_tensor[:, idx, :].cuda(), Ptrain_time_tensor[:, idx].cuda(), \\\n",
    "                                                   None, ytrain_tensor[idx].cuda()\n",
    "\n",
    "                        lengths = torch.sum(Ptime > 0, dim=0)\n",
    "\n",
    "                        #print(P)\n",
    "                        #print(Ptime)\n",
    "                        #print(static_info)\n",
    "                        #print(Pstatic)\n",
    "                        #print(Pstatic.shape)\n",
    "\n",
    "                        outputs = evaluate_standard(model, P, Ptime, Pstatic, static=None)\n",
    "\n",
    "                        #print(outputs)\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "                        loss = criterion(outputs, y)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    if dataset == 'P12' or dataset == 'P19' or dataset == 'eICU':\n",
    "                        train_probs = torch.squeeze(torch.sigmoid(outputs))\n",
    "                        train_probs = train_probs.cpu().detach().numpy()\n",
    "                        train_y = y.cpu().detach().numpy()\n",
    "                        train_auroc = roc_auc_score(train_y, train_probs[:, 1])\n",
    "                        train_auprc = average_precision_score(train_y, train_probs[:, 1])\n",
    "                    elif dataset == 'PAM':\n",
    "                        train_probs = torch.squeeze(nn.functional.softmax(outputs, dim=1))\n",
    "                        train_probs = train_probs.cpu().detach().numpy()\n",
    "                        train_y = y.cpu().detach().numpy()\n",
    "                        train_auroc = roc_auc_score(one_hot(train_y), train_probs)\n",
    "                        train_auprc = average_precision_score(one_hot(train_y), train_probs)\n",
    "\n",
    "                    if wandb:\n",
    "                        wandb.log({ \"train_loss\": loss.item(), \"train_auprc\": train_auprc, \"train_auroc\": train_auroc})\n",
    "\n",
    "                    \"\"\"Validation\"\"\"\n",
    "                    model.eval()\n",
    "                    if epoch ==0 or epoch % 1 == 0:\n",
    "                        with torch.no_grad():\n",
    "                            out_val = evaluate_standard(model, Pval_tensor, Pval_time_tensor, Pval_static_tensor, static=static_info)\n",
    "                            out_val = torch.squeeze(torch.sigmoid(out_val))\n",
    "                            out_val = out_val.detach().cpu().numpy()\n",
    "\n",
    "                            val_loss = criterion(torch.from_numpy(out_val), torch.from_numpy(yval.squeeze(1)).long())\n",
    "\n",
    "                            if dataset == 'P12' or dataset == 'P19' or dataset == 'eICU':\n",
    "                                auc_val = roc_auc_score(yval, out_val[:, 1])\n",
    "                                aupr_val = average_precision_score(yval, out_val[:, 1])\n",
    "                            elif dataset == 'PAM':\n",
    "                                auc_val = roc_auc_score(one_hot(yval), out_val)\n",
    "                                aupr_val = average_precision_score(one_hot(yval), out_val)\n",
    "\n",
    "                            print(\"Validation: Epoch %d,  val_loss:%.4f, aupr_val: %.2f, auc_val: %.2f\" % (epoch,\n",
    "                              val_loss.item(), aupr_val * 100, auc_val * 100))\n",
    "\n",
    "                            if wandb:\n",
    "                                wandb.log({ \"val_loss\": val_loss.item(), \"val_auprc\": aupr_val, \"val_auroc\": auc_val})\n",
    "\n",
    "                            scheduler.step(aupr_val)\n",
    "                            if auc_val > best_auc_val:\n",
    "                                best_auc_val = auc_val\n",
    "                                print(\n",
    "                                    \"**[S] Epoch %d, aupr_val: %.4f, auc_val: %.4f **\" % (epoch, aupr_val * 100, auc_val * 100))\n",
    "                                torch.save(model.state_dict(), model_path + arch + '_' + str(split_idx) + '.pt')\n",
    "\n",
    "                end = time.time()\n",
    "                time_elapsed = end - start\n",
    "                print('Total Time elapsed: %.3f mins' % (time_elapsed / 60.0))\n",
    "\n",
    "                \"\"\"Testing\"\"\"\n",
    "                model.load_state_dict(torch.load(model_path + arch + '_' + str(split_idx) + '.pt'))\n",
    "                model.eval()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    out_test = evaluate(model, Ptest_tensor, Ptest_time_tensor, Ptest_static_tensor, n_classes=n_classes, static=None).numpy()\n",
    "                    ypred = np.argmax(out_test, axis=1)\n",
    "\n",
    "                    # Adding zero interaction students\n",
    "                    ytest = np.append(ytest, zero_ytest, axis=0)\n",
    "                    ypred = np.append(ypred, np.zeros([1, len(zero_ytest)]))\n",
    "\n",
    "                    denoms = np.sum(np.exp(out_test), axis=1).reshape((-1, 1))\n",
    "                    probs = np.exp(out_test) / denoms\n",
    "                    \n",
    "                    # Adding zero interaction students\n",
    "                    probs = np.append(probs, np.zeros([len(zero_ytest), 2]), axis=0)\n",
    "\n",
    "                    acc = np.sum(ytest.ravel() == ypred.ravel()) / ytest.shape[0]\n",
    "                    bac = balanced_accuracy_score(ytest.ravel(), ypred.ravel())\n",
    "\n",
    "\n",
    "                    auc = roc_auc_score(ytest, probs[:, 1])\n",
    "                    aupr = average_precision_score(ytest, probs[:, 1])\n",
    "\n",
    "\n",
    "                # store\n",
    "                    results = pd.DataFrame(columns=['course', 'percentile', 'acc', 'bac', 'auc', 'auprc'])\n",
    "                    results.loc[0] = [MOOC, percentile, acc, bac, auc, aupr]\n",
    "                    results.to_csv(f\"../../transformer_results/test_{MOOC}_{percentile}.csv\")\n",
    "                    print(results)\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    #VALIDATION\n",
    "                    out_val = evaluate(model, Pval_tensor, Pval_time_tensor, Pval_static_tensor, n_classes=n_classes, static=None).numpy()\n",
    "                    ypred = np.argmax(out_val, axis=1)\n",
    "\n",
    "                    # Adding zero interaction students\n",
    "                    yval = np.append(yval, zero_yval, axis=0)\n",
    "                    ypred = np.append(ypred, np.zeros([1, len(zero_yval)]))\n",
    "\n",
    "                    denoms = np.sum(np.exp(out_val), axis=1).reshape((-1, 1))\n",
    "                    probs = np.exp(out_val) / denoms\n",
    "                    \n",
    "                    # Adding zero interaction students\n",
    "                    probs = np.append(probs, np.zeros([len(zero_yval), 2]), axis=0)\n",
    "\n",
    "                    acc = np.sum(yval.ravel() == ypred.ravel()) / yval.shape[0]\n",
    "                    bac = balanced_accuracy_score(yval.ravel(), ypred.ravel())\n",
    "\n",
    "\n",
    "                    auc = roc_auc_score(yval, probs[:, 1])\n",
    "                    aupr = average_precision_score(yval, probs[:, 1])\n",
    "\n",
    "\n",
    "                # store\n",
    "                    results_val = pd.DataFrame(columns=['course', 'percentile', 'acc', 'bac', 'auc', 'auprc'])\n",
    "                    results_val.loc[0] = [MOOC, percentile, acc, bac, auc, aupr]\n",
    "                    results_val.to_csv(f\"../../transformer_results/val_{MOOC}_{percentile}.csv\")\n",
    "                    print(results_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b467fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ed5f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e60bb94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db99db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68893eba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b958ff96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
